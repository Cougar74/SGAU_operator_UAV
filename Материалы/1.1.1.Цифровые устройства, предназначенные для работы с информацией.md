---
tags:
Создана: 2025-10-04
---
# Классификация цифровых устройств
## Введение
Выражение **цифровая культура** прочно вошло в современный лексикон. Выражение digital culture имеет несколько значений.
Во-первых, цифровая культура в онтологическом смысле – это особая форма бытия.
Во-вторых, цифровая культура в аксиологическом смысле (с точки зрения ценности) – это набор ценностей современного информационного общества, закодированных в цифре, воплощенных в технических системах и транслируемых с помощью коммуникативных механизмов.
В-третьих, с позиции социально-психологического подхода цифровая культура исследуется как система новых человеческих практик, вызванных процессом цифровизации общественной жизни и публичного пространства. Радикально меняется аудитория: ее активность состоит не только в восприятии и интерпретации, но и в непосредственном участии в процессе производства информации и дистрибуции контента.
Помимо вышеперечисленного, понятие «**цифровая культура**» отражает особый уровень цифровой грамотности и компетентности. Ранее человеку не требовалось умение эффективно работать с большими базами данных, вести поиск, отбирать и обрабатывать нужную информацию с использованием информационных технологий, и лишь сегодня это все более прочно входит в общественную жизнь.

Исследователи этой темы рассматривают 5 уровней цифровой культуры: *материальный уровень* (сами цифровые устройства); *функциональный уровень* (социальные институты, реализующие коммуникацию); *символический уровень* (язык программирования); *ментальный уровень* (привычки работы с цифровыми устройствами и информацией, которые являются отражением личностных установок и ценностей); *духовный уровень* (принципы формирования и поддержки «духовных ценностей в национальном, межнациональном этническом и локальном контекстах»).
### Роль цифровых устройств в современном мире
`Почему важна классификация?`
Цифровая культура сегодня – составная часть общей культуры, направленная на обеспечение информационных потребностей человечества. Мы живем в мире, насыщенном цифровыми устройствами. От смартфона в кармане до мощного суперкомпьютера, рассчитывающего прогноз погоды. Все эти устройства очень разные по своему назначению, возможностям, размерам и стоимости.
Чтобы не запутаться в этом многообразии, нам нужна система. Именно классификация помогает нам:
1. **Понимать** суть устройства, зная его место в общей системе
2. **Сравнивать** устройства между собой по объективным критериям
3. **Выбирать** правильный инструмент для конкретной задачи
## Классификация цифровых устройств

### Классификация по назначению
Самым логичным и распространенным подходом является классификация устройств в зависимости от той **целевой задачи**, для которой они были созданы.
Можно выделить **четыре** крупные категории:
1. Устройства для обработки информации (Вычислительные устройства)
2. Устройства для хранения информации
3. Устройства для передачи и обмена информацией
4. Устройства ввода и вывода информации (Устройства взаимодействия)
#### Устройства для обработки информации
Эти устройства являются "мозгом" цифрового мира. Их главная функция – выполнение программного кода и преобразование данных (вычисления, сортировка, анализ, управление). Здесь наблюдается четкая иерархия по производительности и масштабу решаемых задач.

**Микроконтроллеры**
По своей сути это "компьютер на одной микросхеме". Включает в себя процессор, память и периферийные устройства ввода-вывода.
*Назначение*: Управление конкретным устройством или процессом. Работают по жестко заданной программе.
*Примеры*: Стиральная машина, кофеварка, система управления двигателем в автомобиле, Arduino, STM32.
Ключевая черта: Узкоспециализированность, низкое энергопотребление, низкая стоимость.

**Персональные компьютеры (ПК) и ноутбуки**
Универсальные вычислительные машины, предназначенные для работы одного или нескольких пользователей.
*Назначение*: Широкий спектр задач: от офисной работы и интернет-серфинга до программирования, дизайна и игр.
*Примеры*: Стационарный ПК (десктоп), ноутбук, моноблок.
*Ключевая черта:* Универсальность, баланс между производительностью и стоимостью.

**Серверы**
Мощные компьютеры, предназначенные для предоставления услуг, данных и вычислительных ресурсов в сети.
*Назначение*: Хостинг сайтов, хранение больших данных (Data Storage), запуск корпоративных приложений, облачные вычисления.
*Примеры*: Веб-сервер, файловый сервер, сервер баз данных.
*Ключевая черта*: Высокая надежность, масштабируемость, работа 24/7.

**Мейнфреймы**
Сверхнадежные и производительные компьютеры для обработки огромных транзакционных потоков.
*Назначение*: Банковские операции, авиабилеты, крупные базы данных государственных учреждений.
*Ключевая черта:* Высокая отказоустойчивость и пропускная способность ввода-вывода.

**Суперкомпьютеры**
Устройства с экстремальной вычислительной мощностью, объединяющие тысячи процессоров.
*Назначение*: Научные расчеты: моделирование климата, квантовая физика, расшифровка генома, аэродинамические simulation.
*Ключевая черта:* Пиковая производительность (измеряется в FLOPS - операций с плавающей точкой в секунду).

#### Устройства для хранения информации
Эти устройства – "цифровая память". Они отвечают за долговременное сохранение данных после отключения питания.
Классифицируем их по архитектуре и назначению:
**Локальные хранилища**
- **Жесткие диски (HDD):** Используют магнитные пластины. Большой объем, низкая стоимость за гигабайт, но чувствительны к ударам и относительно медленные.
- **Твердотельные накопители (SSD):** Используют флеш-память. Очень высокая скорость, бесшумность, устойчивость к ударам. Дороже HDD.
- **Оптические диски (CD/DVD/Blu-ray):** Устаревающий, но дешевый способ хранения и распространения информации.
**Сетевые и внешние хранилища**
- **Внешние HDD/SSD:** Для переноса данных и резервного копирования.
- **Сетевые хранилища (NAS - Network Attached Storage):** Специализированное устройство, подключаемое к сети, предоставляет доступ к данным множеству пользователей.
- **Облачные хранилища:** Данные физически расположены на серверах провайдера (Яндекс.Диск, Google Drive). Доступ через интернет.

#### Устройства для передачи и обмена информацией
Эти устройства образуют "нервную систему" цифрового мира, обеспечивая связь между другими устройствами.
- **Маршрутизаторы (Routers):** "Сортировочные центры" сетей. Определяют оптимальный путь для пакетов данных между разными сетями (например, между вашей домашней сетью и интернетом).
- **Коммутаторы (Switches):** "Распределительные щиты" внутри одной сети. Обеспечивают связь между несколькими устройствами в локальной сети (LAN).
- **Модемы:** Преобразуют цифровые сигналы в аналоговые и обратно для передачи по конкретным каналам связи (например, по телефонной линии или коаксиальному кабелю).
- **Точки доступа Wi-Fi (Access Points):** Создают беспроводную сеть, позволяя устройствам подключаться к проводной сети без кабеля.

#### Устройства ввода и вывода информации
Эти устройства являются "органами чувств и действиями" цифровой системы. Они обеспечивают интерфейс между человеком и машиной.

**Устройства ввода (Input)**
Преобразуют действия пользователя или данные из внешнего мира в цифровой сигнал.
- Клавиатура, мышь, тачпад.
- Микрофон, веб-камера, сканер.
- Сенсорные экраны, датчики (температуры, движения).
**Устройства вывода (Output)**
Преобразуют цифровой сигнал в форму, понятную человеку.
- Монитор, проектор.
- Принтер, плоттер.
- Акустические колонки, наушники.

#### Конвергенция
Важно отметить, что в современном мире границы между этими категориями часто размыты. Ярчайший пример – **смартфон**.
- Это и **устройство обработки** (мощный процессор).
- И **устройство хранения** (внутренняя память и карта памяти).
- И **устройство передачи** (модем 4G/5G, Wi-Fi, Bluetooth).
- И **устройство ввода/вывода** (сенсорный экран, микрофон, динамик, камеры).
Это явление объединения множества функций в одном устройстве называется **конвергенцией**.

Теперь, когда мы понимаем, какие бывают цифровые устройства, давайте разберемся, как они работают. В основе большинства из них лежит **Принцип программного управления**, который мы и рассмотрим далее.

---
# Принцип программного управления
## Принцип программного управления
Мы только что классифицировали устройства по их *назначению*. Но что объединяет микроконтроллер в чайнике и суперкомпьютер?
**Принцип программного управления** - это архитектура вычислительной машины, в которой процесс вычислений определяется программой, хранящейся в памяти устройства.

В основу построения подавляющего большинства компьютеров положены следующие общие принципы, сформулированные в 1945 г. американским ученым Джоном фон Нейманом. 
- **Принцип двоичности** – для представления данных и команд используется двоичная система счисления.
- **Принцип программного управления** – программа состоит из набора команд, которые выполняются процессором друг за другом в определённой последовательности.
- **Принцип однородности памяти** – как программы (команды), так и данные хранятся в одной и той же памяти. Над командами можно выполнять такие же действия, как и над данными.
- **Принцип адресуемости памяти** – структурно основная память состоит из пронумерованных ячеек; процессору в произвольный момент времени доступна любая ячейка.
- **Принцип последовательного программного управления** – все команды располагаются в памяти и выполняются последовательно, одна после завершения другой.
- **Принцип условного перехода** – команды из программы не всегда выполняются одна за другой. Возможно присутствие в программе команд условного перехода, которые изменяют последовательность выполнения команд в зависимости от значений данных.

Первый американский компьютер **EDVAC** (Electronic Discrete Variable Automatic Computer) с новой архитектурой был завершен только в 1949 году. Он весил около 8 тонн и занимал 45 квадратных метров.
![[Pasted image 20251010084144.png]]
EDVAC в Лаборатории баллистических исследований

Компьютер использовал двоичную систему счисления и умел проводить операции сложения, вычитания и деления. Объём памяти составлял 1024 слова – то есть около 5,5 килобайт. Причём в памяти хранились уже не только данные, но и сама программа.
EDVAC установили в Лаборатории баллистических исследований армии США – его работа была строго засекречена. Машина проработала до 1961 года, пока её не заменили на более современную.

Преимущества архитектуры фон Неймана:
- **Простота и универсальность** – архитектура фон Неймана предлагает простую и понятную модель, которая может быть применена к различным типам вычислительных задач.
- **Единая память** – программа и данные хранятся в одной и той же памяти, что упрощает процесс передачи данных между программами и их инструкциями.
- **Легкость в реализации** – архитектура фон Неймана достаточно проста для реализации, что сделало ее популярной в ранних вычислительных системах.
- **Гибкость** – позволяет динамически загружать и изменять программы, что облегчает разработку и обновление программного обеспечения.
- **Широкая поддержка** – большинство современных языков программирования и операционных систем основаны на принципах архитектуры фон Неймана.
Недостатки архитектуры фон Неймана:
- **Узкое место шины** – поскольку программа и данные используют одну и ту же шину для передачи информации, это может привести к узкому месту, когда процессор ожидает данные, что снижает производительность.
- **Проблемы с параллелизмом** – архитектура фон Неймана не поддерживает эффективное выполнение нескольких инструкций одновременно, что ограничивает производительность в многозадачных средах.
- **Ограниченная производительность** – в современных системах, где требуются высокие вычислительные мощности, архитектура фон Неймана может оказаться недостаточной для достижения необходимой производительности.

Изложенные принципы программного управления (фон Неймана) реализовывались в аппаратном обеспечении, структура которого постепенно оформилась.
**Структура компьютера** – это совокупность компонентов компьютера, а также взаимосвязь между ними. Схема, ставшая к настоящему времени классической и включающую:
- блок для выполнения логических и арифметических операций (АЛУ);
- блок для хранения информации (память) или ОЗУ;
- устройства для ввода и вывода данных.
![[Pasted image 20251011174826.png]]
С помощью какого-либо устройства ввода в ЗУ вводится программа. УУ считывает содержимое ячейки памяти ЗУ, где находится первая команда, и организует ее выполнение. Эта команда может задавать выполнение арифметических и логических операций над данными с помощью АЛУ, чтение из памяти данных для выполнения этих операций, вывод данных на устройство вывода и т. д. Затем выполняется вторая команда, третья и т. д. УУ выполняет инструкции программы автоматически.

## Архитектура "Устройство + ПО"
В современных информационных технологиях компьютер используется в качестве основного технического средства для обработки информации.
**Компьютером** называется *техническая система*, предназначенная для автоматизации процесса обработки информации и вычислений на основе принципа программного управления. Термин «техническая система» подчеркивает взаимосвязь аппаратных и программных средств компьютера.
### Аппаратное обеспечение (Hardware)
Аппаратные средства представляет собой совокупность технических устройств, обеспечивающих процесс функционирования компьютера. Аппаратные средства часто называют хардом, устоявшимся сленгом в русском языке (от англ. hardware).
### Программное обеспечение (Software)
Программные средства представляют собой совокупность программ, обеспечивающих процесс обработки информации на компьютере. Программные средства часто называют сленговым словом «софт» (от англ. software).
### Взаимосвязь
Приблизительно каждые два года происходит замена аппаратных и программных средств компьютера новыми, причем общемировая тенденция направлена на сокращение этих сроков. 
В этой связи любая классификация компьютеров является условной, поскольку некоторые свойства, которые были характерными для определенных групп (классов) компьютеров в прошлом, утрачивают эти свойства со временем.
Принципиально может быть бесконечно много классификационных признаков. Выделим наиболее существенные признаки и проведем по ним классификацию.

| Признак                                       | Классы                                                                          |
| --------------------------------------------- | ------------------------------------------------------------------------------- |
| Этапы развития (время создания)               | Первое поколение<br>Второе поколение<br>Третье поколение<br>Четвертое поколение |
| Форма представления обрабатываемой информации | Цифровые<br>Аналоговые<br>Гибридные                                             |
| Назначение                                    | Профессиональные<br>Персональные<br>Специализированные                          |
| Архитектура                                   | С отрытой архитектурой<br>С закрытой архитектурой                               |

**По времени создания** компьютеры подразделяют на поколения (первое, второе, третье и четвертое), которые характеризуются степенью развития аппаратных и программных средств:
- *первое поколение* – середина 40-х и концу 50-х гг. XX в. (1946 г. был создан первый цифровой электронный компьютер ENIAC). В качестве элементной базы использовались электронные лампы, программирование осуществлялось в машинных кодах. Программа вводилась в компьютер путем соединения соответствующих гнезд на специальных наборных платах с помощью электрических проводников. Максимальное быстродействие достигало 20 тыс. операций в секунду.
- *второе поколение* – конец 50-х и середина 60- х гг. XX в. В качестве элементной базы использовались полупроводниковые 6 приборы – транзисторы, что позволило повысить надежность и быстродействие компьютеров. Программирование осуществлялось на языках программирования высокого уровня. Программа вводилась в компьютер с помощью перфокарт и перфолент. Максимальное быстродействие составляло до 1 млн операций в секунду.
- *третье поколение* – с середины 60-х по середину 70-х гг. XX в. В качестве элементной базы использовались интегральные микросхемы среднего уровня интеграции. Программирование осуществлялось на языках программирования высокого уровня. Программа вводилась в компьютер с помощью перфокарт и перфолент, появились накопители информации на гибких магнитных дисках. Максимальное быстродействие составляло около 1 млн операций в секунду. Компьютеры третьего поколения стали семейством компьютеров с единой архитектурой, что обеспечило их программную совместимость. Они имели развитые операционные системы и обладали возможностями мультипрограммирования.
- *четвертое поколение* – с середины 70-х гг. XX в. по настоящее время. В качестве элементной базы использовались большие интегральные микросхемы (БИС), а затем (в настоящее время) сверхбольшие интегральные микросхемы (СБИС), что позволило существенно повысить надежность и быстродействие компьютеров. На основе БИС, а затем и СБИС строились и строятся микропроцессоры – устройства для непосредственного выполнения процесса обработки данных и программного управления этим процессом. Программирование осуществлялось и осуществляется на нескольких десятках языков программирования высокого уровня, включая и объектно-ориентированные языки программирования. Программы вводились и вводятся в компьютер с помощью разнообразных носителей информации – накопителей на гибких магнитных дисках, жестких магнитных дисков, оптических дисков и т. д. Максимальное быстродействие компьютеров четвертого поколения составляет около 1 трлн операций в секунду.

| Год выпуска | Название компьютера  | Создатель                | Примечания                                                               |
| ----------- | -------------------- | ------------------------ | ------------------------------------------------------------------------ |
| 1834        | Аналитическая машина | Бэббидж                  | Первая попытка построить цифровой компьютер                              |
| 1936        | Z1                   | Зус                      | Первая релейная вычислительная машина                                    |
| 1943        | COLOSSUS             | Британское правительство | Первый электронный компьютер                                             |
| 1944        | Mark I               | Айкен                    | Первый американский компьютер общего назначения                          |
| 1946        | ENIAC 1              | Экерт/Мокли              | С этой машины начинается история современных компьютеров                 |
| 1949        | EDSAC                | Уилке                    | Первый компьютер с программами, хранящимися в памяти                     |
| 1951        | Whirlwind 1          | МТИ                      | Первый компьютер реального времени                                       |
| 1952        | IAS                  | Фон Нейман               | Эта архитектура используется в большинстве современных компьютеров       |
| 1960        | PDP-1                | DEC                      | Первый мини-компьютер (продано 50 экземпляров)                           |
| 1961        | 1401                 | IBM                      | Очень популярный компьютер для малого бизнеса                            |
| 1962        | 7094                 | IBM                      | Лидер в области научных расчетов начала 1960-х годов                     |
| 1963        | B5000                | Burroughs                | Первая машина, разработанная для языка высокого уровня                   |
| 1964        | 360                  | IBM                      | Первое семейство компьютеров                                             |
| 1964        | 6600                 | CDC                      | Первый суперкомпьютер для научных расчетов                               |
| 1965        | PDP-8                | DEC                      | Первый мини-компьютер массового потребления (продано 50 000 экземпляров) |
| 1970        | PDP-11               | DEC                      | Эти мини-компьютеры доминировали на компьютерном рынке в 70-е годы       |
| 1974        | 8080                 | Intel                    | Первый универсальный 8-разрядный компьютер на микросхеме                 |
| 1974        | CRAY-1               | Cray                     | Первый векторный суперкомпьютер                                          |
| 1978        | VAX                  | DEC                      | Первый 32-разрядный супермини-компьютер                                  |
| 1981        | IBM PC               | IBM                      | Началась эра современных персональных компьютеров                        |
| 1981        | Osborne-1            | Osborne                  | Первый портативный компьютер                                             |
| 1983        | Lisa                 | Apple                    | Первый ПК с графическим пользовательским интерфейсом                     |
| 1985        | 386                  | Intel                    | Первый 32-разрядный предшественник линейки Pentium                       |
| 1985        | MIPS                 | MIPS                     | Первый компьютер RISC                                                    |
| 1985        | XC2064               | Xilinx                   | Первая программируемая вентильная матрица (FPGA)                         |
| 1987        | SPARC                | Sun                      | Первая рабочая станция RISC на основе процессора SPARC                   |
| 1989        | GridPad              | Grid Systems             | Первый коммерческий планшетный компьютер                                 |
| 1990        | RS6000               | IBM                      | Первый суперскалярный компьютер                                          |
| 1992        | Alpha                | DEC                      | Первый 64-разрядный ПК                                                   |
| 1992        | Simon                | IBM                      | Первый смартфон                                                          |
| 1993        | Newton               | Apple                    | Первый карманный компьютер                                               |
| 2001        | POWER4               | IBM                      | Первая двухъядерная многопроцессорная микросхема                         |

По форме представления обрабатываемой информации все компьютеры можно разделить на три крупных класса: **цифровые**, **аналоговые** и **гибридные**.
**Цифровые вычислительные машины (ЦВМ)**

Открытая архитектура ПК позволяет пользователю свободно менять и добавлять компоненты от разных производителей, так как спецификации системы доступны публично. Закрытая архитектура предполагает, что все компоненты производит одна компания, что ограничивает возможности модернизации и выбор.

### Первое поколение – электронные лампы (1945–1955)
Стимулом к созданию электронного компьютера стала Вторая мировая война. В начале войны германские подводные лодки наносили серьезный ущерб британскому флоту. Германские адмиралы посылали на подводные лодки по радио команды, и хотя англичане могли перехватывать эти команды, проблема была в том, что радиограммы были закодированы с помощью прибора под названием **ENIGMA**, предшественник которого был спроектирован изобретателем дилетантом и бывшим президентом США Томасом Джефферсоном.
В начале войны англичанам удалось приобрести ENIGMA у поляков, которые, в свою очередь, украли ее у немцев. Однако чтобы расшифровать закодированное послание, требовалось огромное количество вычислений, и их нужно было произвести сразу после перехвата радиограммы. Поэтому британское правительство основало секретную лабораторию для создания электронного компьютера под названием COLOSSUS. В создании этой машины принимал участие знаменитый британский математик Алан Тьюринг. COLOSSUS работал уже в 1943 году, но так как британское правительство полностью контролировало этот проект и рассматривало его как военную тайну на протяжении 30 лет, COLOSSUS не стал базой для дальнейшего развития компьютеров. Мы упомянули о нем только потому, что это был первый в мире электронный цифровой компьютер.

В 1943 году Джон Мокли со своим студентом Дж. Преспером Эккертом (J. Presper Eckert) начали конструировать электронный компьютер, который они назвали ENIAC (Electronic Numerical Integrator and Computer – электронный цифровой интегратор и калькулятор). ENIAC состоял из 18 000 электровакуумных ламп и 1500 реле, весил 30 тон и потреблял 140 киловатт электроэнергии. У машины было 20 регистров, каждый из которых мог содержать 10-разрядное десятичное число. (Десятичный регистр – это память очень маленького объема, которая может вмещать число до какого-либо определенного максимального количества разрядов, что-то вроде одометра, запоминающего километраж пройденного автомобилем пути.) Программирование ENIAC осуществлялось при помощи 6000 многоканальных переключателей и многочисленных кабелей, подключавшихся к разъемам.
Работа над машиной была закончена в 1946 году, когда она уже была не нужной – по крайней мере, для достижения первоначально поставленных целей. Поскольку война закончилась, Мокли и Эккерту позволили организовать школу, где они рассказывали о своей работе коллегам-ученым. В этой школе и зародился интерес к созданию больших цифровых компьютеров.

После появления школы за конструирование электронных вычислительных машин взялись другие исследователи. Первым рабочим компьютером был EDSAC (1949 год). Эту машину сконструировал Морис Уилкс в Кембриджском университете. Далее – JOHNNIAC в корпорации Rand, ILLIAC в университете Иллинойса, MANIAC в лаборатории Лос-Аламоса и WEIZAC в институте Вайцмана в Израиле.
Эккерт и Мокли вскоре начали работу над машиной EDVAC (Electronic Discrete Variable Computer – электронная дискретная параметрическая машина). К несчастью, этот проект закрылся, когда они ушли из университета, чтобы основать компьютерную корпорацию в Филадельфии (Силиконовой долины тогда еще не было). После ряда слияний эта компания превратилась в Unisys Corporation.

В то время как Эккерт и Мокли работали над машиной EDVAC, один из участников проекта ENIAC, Джон фон Нейман, поехал в Институт специальных исследований в Принстоне, чтобы сконструировать собственную версию EDVAC под названием IAS (Immediate Address Storage – память с прямой адресацией). Фон Нейман был гением того же уровня, что и Леонардо да Винчи. Он знал много языков, был специалистом в физике и математике, обладал феноменальной памятью: он помнил все, что когда-либо слышал, видел или читал. Он мог дословно процитировать по памяти текст книг, которые читал несколько лет назад. Когда фон Нейман стал интересоваться вычислительными машинами, он уже был самым знаменитым математиком в мире.
Фон Нейман вскоре осознал, что программирование компьютеров с большим количеством переключателей и кабелей – занятие медленное, утомительное и неудобное. Он пришел к мысли, что программа должна быть представлена в памяти компьютера в цифровой форме, вместе с данными. Он также отметил, что десятичная арифметика, используемая в машине ENIAC, где каждый разряд представлялся десятью электронными лампами (1 включена и 9 выключены), может быть заменена параллельной двоичной арифметикой.

Примерно в то же время, когда фон Нейман работал над машиной IAS, исследователи МТИ разрабатывали свой компьютер Whirlwind I. В отличие от IAS, ENIAC и других машин того же типа со словами большой длины, предназначенными для серьезных вычислений, машина Whirlwind I имела слова по 16 бит и предназначалась для работы в реальном времени. Этот проект привел к изобретению Джеем Форрестером (Jay Forrester) памяти на магнитном сердечнике, а затем и первого серийного мини-компьютера.
В то время IBM была маленькой компанией, производившей перфокарты и механические машины для сортировки перфокарт. И только в 1953 году построила компьютер 701. В 701 было 2048 слов по 36 бит, каждое слово содержало две команды. Это была первая машина из серии, которая заняла лидирующее положение на рынке в течение ближайших десяти лет. Через три года появился компьютер 704, у которого было 4096 слов памяти, команды по 36 бит и процессор для вычислений с плавающей точкой. В 1958 году компания IBM начала работу над последним компьютером на электронных лампах, 709, который по сути представлял собой усовершенствованную версию 704.
### Второе поколение – транзисторы (1955–1965)
Транзистор был изобретен сотрудниками лаборатории Bell Laboratories Джоном Бардином ( John Bardeen), Уолтером Браттейном (Walter Brattain) и Уильямом Шокли (William Shockley), за что в 1956 году они получили Нобелевскую премию в области физики. В течение десяти лет транзисторы произвели революцию в производстве компьютеров, и к концу 50-х годов компьютеры на вакуумных лампах стали пережитком прошлого. Первый компьютер на транзисторах был построен в лаборатории МТИ. Он содержал слова из 16 бит, как и Whirlwind I. Компьютер назывался **TX-0** (Transistorized eXperimental computer 0 – экспериментальная транзисторная вычислительная машина 0) и предназначался только для тестирования будущей машины TX-2.
Машина TX-2 не имела большого значения, но один из инженеров из этой лаборатории, Кеннет Ольсен (Kenneth Olsen), в 1957 году основал компанию DEC (Digital Equipment Corporation – корпорация по производству цифровой аппаратуры) для производства серийной машины, сходной с TX-0. Эта машина, PDP-1, появилась только через четыре года главным образом потому, что те, кто финансировал DEC, считали, что у производства компьютеров нет будущего. В конце концов, Т. Дж. Уотсон, бывший президент IBM, однажды сказал, что мировой рынок компьютеров составляет четыре или пять единиц. Поэтому компания DEC продавала в основном небольшие электронные платы.
Компьютер PDP-1 появился только в 1961 году. Он имел 4096 слов по 18 бит и быстродействие 200 000 команд в секунду. Этот параметр был в два раза меньше, чем у 7090, транзисторного аналога 709 и самого быстрого компьютера в мире на то время. Но PDP-1 стоил 120 000 долларов, в то время как 7090 стоил миллионы. Компания DEC продала десятки компьютеров PDP-1, и так появилась компьютерная промышленность.
Одну из первых машин модели PDP-1 отдали в МТИ, где она сразу привлекла внимание некоторых молодых исследователей, подающих большие надежды. Одним из нововведений PDP-1 был дисплей с размером 512х512 пикселов, на котором можно было рисовать точки. Вскоре студенты МТИ составили специальную программу для PDP-1, чтобы играть в «Космическую войну» – первую в мире компьютерную игру.
Через несколько лет компания DEC разработала модель PDP-8, 12-разрядный компьютер. PDP-8 стоил гораздо дешевле, чем PDP-1 (16 000 долларов). Главное нововведение – единственная шина (omnibus). **Шина** – это набор параллельно соединенных проводов, связывающих компоненты компьютера. Это нововведение радикально отличало PDP-8 от IAS. Такая архитектура с тех пор стала использоваться во всех малых компьютерах. Компания DEC продала 50 000 компьютеров модели PDP-8 и стала лидером на рынке мини-компьютеров.
![[Pasted image 20251019173257.png]]
Как уже отмечалось, с изобретением транзисторов компания IBM построила транзисторную версию 709 – 7090, а позднее – 7094. У этой версии время цикла составляло 2 микросекунды, а память состояла из 32 536 слов по 36 бит. 7090 и 7094 были последними компьютерами типа ENIAC, но они занимали ведущее положение в области научных расчетов в 60-х годах прошлого века.
В то же время компания IBM зарабатывала большие деньги на продаже небольших компьютеров 1401 для коммерческих расчетов. Эта машина могла считывать и записывать магнитные ленты и перфокарты и распечатывать результат так же быстро, как и 7094, но при этом стоила дешевле. Для научных вычислений она не подходила, но зато была очень удобна для коммерческого учета.
Архитектура 1401 была необычной тем, что в ней не было регистров и даже фиксированной длины слова. Память содержала 4000 байт по 8 бит (в более поздних моделях объем увеличился до немыслимых в то время 16 000 байт). Каждый байт содержал символ в 6 бит, административный бит и бит для обозначения конца слова. Команда MOVE, например, использовала два адреса: источника и приемника. Она перемещала байты из источника в приемник, пока не обнаруживала бит конца слова, установленный в 1.
В 1964 году маленькая, никому не известная компания CDC (Control Data Corporation) выпустила машину 6600, которая работала почти на порядок быстрее, чем 7094 (и все остальные машины того времени). Этот компьютер для сложных расчетов пользовался большой популярностью, и компания CDC пошла «в гору». Секрет столь высокого быстродействия заключался в том, что внутри ЦП (центрального процессора) находилась машина с высокой степенью параллелизма. У нее было несколько функциональных устройств для сложения, умножения и деления, и все они могли работать одновременно. Хотя быстрая работа машины требовала тщательной работы программиста, при определенных усилиях можно было сделать так, чтобы машина исполняла 10 команд одновременно.
### Третье поколение – интегральные схемы (1965–1980)
Изобретение кремниевой интегральной схемы в 1958 году Джеком Килби (Jack Kilby) и Робертом Нойсом (Robert Noyce) позволило разместить на одной небольшой микросхеме десятки транзисторов. Компьютеры на интегральных схемах были меньшего размера, работали быстрее и стоили дешевле, чем их предшественники на транзисторах.
К 1964 году компания IBM лидировала на компьютерном рынке, но существовала одна большая проблема: выпускаемые ей компьютеры 7094 и 1401, исключительно успешные и прибыльные, были несовместимы друг с другом. Один из них предназначался для сложных расчетов, в нем использовались параллельные двоичные операции с регистрами по 36 бит, во втором применялась десятичная система счисления и слова переменной длины. У многих покупателей были оба этих компьютера и им не нравилась необходимость содержать два разных отдела программирования, не имевшие ничего общего.

Когда пришло время заменить эти две серии компьютеров, компания IBM сделала решительный шаг. Она выпустила линейку транзисторных компьютеров System/360, которые были предназначены как для научных, так и для коммерческих расчетов. Линейка System/360 имела много нововведений. Это было целое семейство компьютеров для работы с одним языком (ассемблером), разного размера и вычислительной мощности. Компания смогла заменить 1401 на 360 (модель 30), а 7094 – на 360 (модель 75). Модель 75 была больше по размеру, работала быстрее и стоила дороже, но программы, написанные для одной из них, теоретически могли использоваться в другой. На практике программы, написанные для маленькой модели, исполнялись большой моделью без особых затруднений. Но в случае переноса программного обеспечения с большой машины на маленькую могло не хватить памяти. И все же создание такой линейки компьютеров было большим достижением. Идея создания семейств компьютеров вскоре стала очень популярной, и в течение нескольких лет большинство компьютерных компаний выпустили серии сходных машин с разной стоимостью и функциями. В таблице показаны некоторые параметры первых моделей из семейства 360.

**Таблица**. Первые модели серии IBM 360

| Параметры                                            | Модель 30 | Модель 40 | Модель 50 | Модель 65 |
| ---------------------------------------------------- | --------- | --------- | --------- | --------- |
| Относительная производительность                     | 1         | 3,5       | 10        | 21        |
| Время цикла, нс                                      | 1000      | 625       | 500       | 250       |
| Максимальный объем памяти, байт                      | 65 536    | 262 144   | 262 144   | 524 288   |
| Количество байтов, вызываемых из памяти за один цикл | 1         | 2         | 4         | 16        |
| Максимальное количество каналов данных               | 3         | 3         | 4         | 6         |

Еще одно нововведение в 360 – **многозадачность**. В памяти компьютера могло находиться одновременно несколько программ, и пока одна программа ждала, когда закончится процесс ввода-вывода, другая исполнялась. В результате ресурсы процессора расходовались более рационально.
Компьютеру 360 удалось разрешить дилемму между двоичной и десятичной системами счисления: у этого компьютера было 16 регистров по 32 бит для двоичных операций, но память состояла из байтов, как у 1401. В 360 использовались такие же команды для перемещения записей переменного размера между блоками памяти, как и в 1401.
Другой особенностью 360 было громадное (на то время) адресное пространство 224 байт (16 Мбайт). В те дни, когда байт памяти стоил несколько долларов, это казалось бесконечностью. К сожалению, линейка 360 позднее сменилась линейкой 370, затем 4300, 3080, 3090, и все эти компьютеры имели сходную архитектуру. К середине 80-х годов 16 Мбайт памяти стало недостаточно, и компании IBM пришлось частично отказаться от совместимости, чтобы перейти на 32-разрядную адресацию, необходимую для памяти объемом в 232 байт.

### Четвертое поколение – сверхбольшие интегральные схемы (1980 - ?)
Появление сверхбольших интегральных схем (**СБИС**) в 80-х годах позволило размещать на одной плате сначала десятки тысяч, затем сотни тысяч и, наконец, миллионы транзисторов. Это привело к созданию компьютеров меньшего размера и более быстродействующих. До появления PDP-1 компьютеры были настолько большие и дорогостоящие, что компаниям и университетам приходилось иметь специальные отделы (**вычислительные центры**). К 80-м годам цены упали так сильно, что возможность приобретать компьютеры появилась не только у организаций, но и у отдельных людей. Началась эра персональных компьютеров.
Персональные компьютеры требовались совсем для других целей, чем их предшественники. Они применялись для обработки слов, электронных таблиц, а также для исполнения приложений с высоким уровнем интерактивности (например, игр), для которых большие компьютеры не подходили.
Первые персональные компьютеры продавались в виде комплектов. Каждый комплект содержал печатную плату, набор интегральных схем, обычно включая схему Intel 8080, несколько кабелей, источник питания и иногда 8-дюймовый дисковод. Сложить из этих частей компьютер покупатель должен был сам. Программное обеспечение к компьютеру не прилагалось. Покупателю приходилось писать программное обеспечение самому. Позднее появилась операционная система CP/M, написанная Гари Килдаллом (Gary Kildall) для Intel 8080. Это была полноценная операционная система (на дискете), со своей файловой системой и интерпретатором для исполнения пользовательских команд, которые вводились с клавиатуры.
Еще один персональный компьютер, Apple (а позднее и Apple II), был разработан Стивом Джобсом (Steve Jobs) и Стивом Возняком (Steve Wozniak). Этот компьютер стал чрезвычайно популярным среди домашних пользователей и школ, что в мгновение ока сделало компанию Apple серьезным игроком на рынке.

Хотя некоторые компании (такие как Commodore, Apple и Atari) производили персональные компьютеры с использованием своих процессоров, а не процессоров Intel, потенциал производства IBM PC был настолько велик, что другим компаниям приходилось пробиваться с трудом. Выжить удалось только некоторым из них, и то лишь потому, что они специализировались в узких областях, например в производстве рабочих станций или суперкомпьютеров.
Одной из таких выживших (хотя и с трудом) моделей стал компьютер Apple Macintosh. Он появился в 1984 году как наследник злополучного Apple Lisa — первого компьютера с графическим интерфейсом, сходным с интерфейсом популярной ныне системы Windows. Неудача Lisa объяснялась дороговизной, но более дешевый Macintosh, появившийся через год, пользовался огромным успехом и завоевал много преданных поклонников.

Ранний рынок персональных компьютеров также привел к неслыханному спросу на портативные компьютеры. В то время портативный компьютер казался такой же нелепицей, как и портативный холодильник. Первый портативный компьютер — Osborne-1 — весил 11 килограммов, и носить его с собой было, мягко говоря, неудобно. Тем не менее само появление этой модели доказало, что это возможно. Коммерческий успех Osborne-1 был довольно скромным, но через год фирма Compaq представила свой первый портативный клон IBM PC и быстро завоевала место лидера на рынке портативных компьютеров.

Первая версия IBM PC была оснащена операционной системой MS-DOS, которую выпускала тогда еще крошечная корпорация Microsoft. Благодаря тому, что фирма Intel выпускала все более мощные процессоры, IBM и Microsoft совместно разработали последовавшую за MS-DOS операционную систему OS/2, отличительной особенностью которой был **графический пользовательский интерфейс** (Graphical User Interface, **GUI**), сходный с интерфейсом Apple Macintosh. Между тем компания Microsoft также разработала собственную операционную систему Windows, которая работала на основе MS-DOS, — на случай, если OS/2 не будет иметь спроса. Короче говоря, OS/2 действительно не пользовалась спросом, а Microsoft успешно продолжала выпускать операционную систему Windows, что послужило причиной грандиозного раздора между IBM и Microsoft. История о том, как крошечная компания Intel и еще меньшая компания Microsoft умудрились свергнуть IBM, одну из самых крупных, самых богатых и самых влиятельных корпораций в мировой истории, подробно излагается в бизнес-школах всего мира.
Первоначальный успех процессора 8088 воодушевил компанию Intel на его дальнейшие усовершенствования. Особо примечательна версия 80386, выпущенная в 1985 году, — этот процессор был уже 32-разрядным. За ней последовал улучшенный вариант, который, естественно, назывался 80486. Последующие версии назывались Pentium и Core. Эти микросхемы используются практически во всех современных PC. Архитектура процессоров этого семейства часто обозначается общим термином **x86**. Совместимые микросхемы, производимые фирмой AMD, тоже называются x86.

В середине 80-х годов на смену CISC (Complex Instruction Set Computer — компьютер с полным набором команд) пришли компьютеры RISC (Reduced Instruction Set Computer — компьютер с сокращенным набором команд). RISC команды были проще и выполнялись гораздо быстрее. В 90-х годах появились суперскалярные процессоры, которые могли исполнять много команд одновременно, часто не в том порядке, в котором они располагаются в программе.

В 1990-е годы компьютерные системы ускорялись посредством различных микроархитектурных оптимизаций, многие из которых будут рассмотрены в книге. Пользователи таких систем пребывали в благодушном настроении, потому что в каждой новой купленной системе их программы работали намного быстрее, чем в старой. Однако к концу 1990-х годов тенденция к повышению скорости стала снижаться из-за двух важных препятствий в области проектирования: архитекторы исчерпали запас возможностей для ускорения программ, а охлаждение процессоров стало обходиться слишком дорого. Многие компьютерные компании, отчаянно стремившиеся к построению более быстрых процессоров, обратились к параллельным архитектурам как к средству выжать больше быстродействия из своей электроники. В 2001 году фирма IBM представила двухъядерную архитектуру POWER4 — первый образец крупносерийного центрального процессора, включавшего два процессора на одной подложке.

### Закон Мура
По темпам развития компьютерная промышленность опережает все остальные отрасли. Главная движущая сила — способность производителей помещать с каждым годом все больше и больше транзисторов на микросхему. Чем больше транзисторов (крошечных электронных переключателей), тем больше объем памяти и мощнее процессоры. Гордон Мур (Gordon Moore), один из основателей и бывший председатель совета директоров Intel, однажды сострил по поводу того, что если бы авиационные технологии развивались с такой же скоростью, как компьютерные, самолеты стоили бы 500 долларов и облетали землю за 20 минут на 20 литрах топлива. Правда, для этого они должны стать размером с обувную коробку.
Он же сформулировал закон технологического прогресса, известный теперь под именем закона Мура. Когда Гордон готовил доклад для одной из промышленных групп, он заметил, что каждое новое поколение микросхем появляется через три года после предыдущего. Поскольку у каждого нового поколения компьютеров было в 4 раза больше памяти, чем у предыдущего, стало понятно, что число транзисторов на микросхеме возрастает в постоянной пропорции, и таким образом, этот рост можно предсказать на годы вперед. Закон Мура часто представляется в формулировке, которая гласит, что число транзисторов на одной микросхеме удваивается каждые 18 месяцев, то есть увеличивается на 60 % каждый год. Размеры микросхем и даты их производства подтверждают, что закон Мура действует до сих пор.
![[Pasted image 20251019181312.png]]
![[Pasted image 20251019181733.png]]
По большому счету, закон Мура — это никакой не закон, а простое эмпирическое наблюдение о том, с какой скоростью физики и инженеры-технологи развивают компьютерные технологии, и предсказание, что с такой скоростью они будут работать и в будущем.
### Структура современных ЭВМ
Появление третьего поколения ЭВМ было обусловлено переходом от транзисторов к микросхемам. Резко увеличилось быстродействие процессора. Возникло существенное противоречие между высокой скоростью обработки информации внутри машины и медленной работой устройств ввода/вывода. Если бы процессор руководил работой внешних устройств по классической схеме, то значительную часть он был бы вынужден простаивать в ожидании информации, что существенно снижало бы эффективность работы всей ЭВМ в целом.
Структура современных персональных компьютеров отличается от классической структуры компьютера. Основные отличия:
- АЛУ и УУ объединены в единое устройство, называемое микропроцессором (МП, центральный процессор, реализованный на СБИС), кроме того, в состав МП входит ряд других устройств, предназначенных для хранения, записи, считывания и обмена информацией;
- применение специализированных устройств – контроллеров, которым передается часть функций МП, связанная с обменом информации и управлением работой устройств для ввода и вывода (внешних устройств) информации, такая децентрализация позволяет повысить эффективность работы компьютера в целом за счет сокращения времени простоя МП;
- вместо отдельных линий связи между устройствами используется системная магистраль с соответствующими устройствами сопряжения. Наличие системной магистрали в персональном компьютере позволяет осуществить обмен информацией между устройствами компьютера, уменьшить число линий связи, подключить различные дополнительные устройства через соответствующие разъемные соединения и т. д.
Таким образом, с учетом перечисленных особенностей персональный компьютер отвечает принципам открытой архитектуры, и его структура, в которую вошли основные устройства, приобретает вид, представленный на схеме. 
![[Pasted image 20251011175345.png]]
Данная структура была предложена фирмой IBM, поэтому персональные компьютеры, имеющие такую структуру, называются IBM – совместимые (IBM PC).
## Зоопарк операционных систем
История операционных систем насчитывает уже более полувека. За это время было разработано огромное количество разнообразных операционных систем, но не все они получили широкую известность. В данном разделе мы вкратце коснемся девяти операционных систем.
### Операционные системы мейнфреймов
К высшей категории относятся операционные системы мейнфреймов. Операционные системы мейнфреймов ориентированы преимущественно на одновременную обработку множества заданий, большинство из которых требует колоссальных объемов ввода-вывода данных. Обычно они предлагают три вида обслуживания: пакетную обработку, обработку транзакций и работу в режиме разделения времени.
Пакетная обработка – это одна из систем обработки стандартных заданий без участия пользователей. В пакетном режиме осуществляется обработка исков в страховых компаниях или отчетов о продажах сети магазинов.
Системы обработки транзакций справляются с большим количеством мелких запросов, к примеру обработкой чеков в банках или бронированием авиабилетов. Каждая элементарная операция невелика по объему, но система может справляться с сотнями и тысячами операций в секунду.
Работа в режиме разделения времени дает возможность множеству удаленных пользователей одновременно запускать на компьютере свои задания, например запросы к большой базе данных. Все эти функции тесно связаны друг с другом, и зачастую операционные системы универсальных машин выполняют их в комплексе.
Примером операционной системы универсальных машин может послужить OS/390, наследница OS/360. Однако эти операционные системы постепенно вытесняются вариантами операционной системы UNIX, например Linux.
### Серверные операционные системы
Чуть ниже по уровню стоят серверные операционные системы. Они работают на серверах, которые представлены очень мощными персональными компьютерами, рабочими станциями или даже универсальными машинами. Они одновременно обслуживают по сети множество пользователей, обеспечивая им общий доступ к аппаратным и программным ресурсам. Серверы могут предоставлять услуги печати, хранения файлов или веб-служб. Интернет-провайдеры для обслуживания своих клиентов обычно задействуют сразу несколько серверных машин. При обслуживании веб-сайтов серверы хранят веб-страницы и обрабатывают поступающие запросы. Типичными представителями серверных операционных систем являются Solaris, FreeBSD, Linux и Windows Server 201x.
### Многопроцессорные операционные системы
Сейчас все шире используется объединение множества центральных процессоров в единую систему, что позволяет добиться вычислительной мощности, достойной высшей лиги. В зависимости от того, как именно происходит это объединение, а также каковы ресурсы общего пользования, эти системы называются параллельными компьютерами, мультикомпьютерами или многопроцессорными системами. Им требуются специальные операционные системы, в качестве которых часто применяются особые версии серверных операционных систем, оснащенные специальными функциями связи, сопряжения и синхронизации.
С недавним появлением многоядерных процессоров для персональных компьютеров операционные системы даже обычных настольных компьютеров и ноутбуков стали работать по меньшей мере с небольшой многопроцессорной системой. Со временем, похоже, число ядер будет только расти. К счастью, за годы предыдущих исследований были накоплены обширные знания о многопроцессорных операционных системах, и использование этого арсенала в многоядерных системах не должно вызвать особых осложнений. Труднее всего будет найти приложения, которые смогли бы использовать всю эту вычислительную мощь. На многопроцессорных системах могут работать многие популярные операционные системы, включая Windows и Linux.
### Операционные системы персональных компьютеров
К следующей категории относятся операционные системы персональных компьютеров. Все их современные представители поддерживают многозадачный режим. При этом довольно часто уже в процессе загрузки на одновременное выполнение запускаются десятки программ. Задачей операционных систем персональных компьютеров является качественная поддержка работы отдельного пользователя. Они широко используются для обработки текстов, создания электронных таблиц, игр и доступа к Интернету. Типичными примерами могут служить операционные системы Linux, FreeBSD, Windows 7, Windows 8 и OS X компании Apple. Операционные системы персональных компьютеров известны настолько широко, что в особом представлении не нуждаются. По сути, многим людям даже невдомек, что существуют другие разновидности операционных систем.
### Операционные системы карманных персональных компьютеров
Продолжая двигаться по нисходящей ко все более простым системам, мы дошли до планшетов, смартфонов и других карманных компьютеров. Эти компьютеры, изначально известные как **КПК**, или PDA (**Personal** Digital Assistant – персональный цифровой секретарь), представляют собой небольшие компьютеры, которые во время работы держат в руке. Самыми известными их представителями являются смартфоны и планшеты. Как уже говорилось, на этом рынке доминируют операционные системы Android от Google и iOS от Apple, но у них имеется множество конкурентов. Большинство таких устройств могут похвастаться многоядерными процессорами, GPS, камерами и другими датчиками, достаточным объемом памяти и сложными операционными системами. Более того, у всех них имеется больше сторонних приложений (apps) для USB-носителей, чем вы себе можете представить.
### Встроенные операционные системы
Встроенные системы работают на компьютерах, которые управляют различными устройствами. Поскольку на этих системах установка пользовательских программ не предусматривается, их обычно компьютерами не считают. Примерами устройств, где устанавливаются встроенные компьютеры, могут послужить микроволновые печи, телевизоры, автомобили, пишущие DVD, обычные телефоны и MP3-плееры. В основном встроенные системы отличаются тем, что на них ни при каких условиях не будет работать стороннее программное обеспечение. В микроволновую печь невозможно загрузить новое приложение, поскольку все ее программы записаны в ПЗУ. Следовательно, отпадает необходимость в защите приложений друг от друга и операционную систему можно упростить. Наиболее популярными в этой области считаются операционные системы Embedded Linux, QNX и VxWorks.
### Операционные системы реального времени
Еще одна разновидность операционных систем — это системы реального времени. Эти системы характеризуются тем, что время для них является ключевым параметром. Например, в системах управления производственными процессами компьютеры, работающие в режиме реального времени, должны собирать сведения о процессе и использовать их для управления станками на предприятии. Довольно часто они должны отвечать очень жестким временным требованиям. Например, когда автомобиль перемещается по сборочному конвейеру, то в определенные моменты времени должны осуществляться вполне конкретные операции. Если, к примеру, сварочный робот приступит к сварке с опережением или опозданием, машина придет в негодность. Если операция должна быть проведена точно в срок (или в определенный период времени), то мы имеем дело с **системой жесткого реального времени**. Множество подобных систем встречается при управлении производственными процессами, в авиационно-космическом электронном оборудовании, в военной и других подобных областях применения. Эти системы должны давать абсолютные гарантии того, что определенные действия будут осуществляться в конкретный момент времени.
Другой разновидностью подобных систем является **система мягкого реального времени**, в которой хотя и нежелательно, но вполне допустимо несоблюдение срока какого-нибудь действия, что не наносит непоправимого вреда. К этой категории относятся цифровые аудио- или мультимедийные системы. Смартфоны также являются системами мягкого реального времени.
Поскольку к системам реального времени предъявляются очень жесткие требования, иногда операционные системы представляют собой простую библиотеку, сопряженную с прикладными программами, где все тесно взаимосвязано и между частями системы не существует никакой защиты. Примером такой системы может послужить eCos.
### Операционные системы смарт-карт
Самые маленькие операционные системы работают на смарт-картах. Смарт-карта представляет собой устройство размером с кредитную карту, имеющее собственный процессор. На операционные системы для них накладываются очень жесткие ограничения по требуемой вычислительной мощности процессора и объему памяти. Некоторые из смарт-карт получают питание через контакты считывающего устройства, в которое вставляются, другие — бесконтактные смарт-карты — получают питание за счет эффекта индукции, что существенно ограничивает их возможности. Некоторые из них способны справиться с одной-единственной функцией, например с электронными платежами, но существуют и многофункциональные смарт-карты. Зачастую они являются патентованными системами.
Некоторые смарт-карты рассчитаны на применение языка Java. Это значит, что ПЗУ смарт-карты содержит интерпретатор Java Virtual Machine (JVM — виртуальная машина Java). На карту загружаются Java-апплеты (небольшие программы), которые выполняются JVM-интерпретатором. Некоторые из этих карт способны справляться сразу с несколькими Java-апплетами, что влечет за собой работу в мультипрограммном режиме и необходимость установки очередности выполнения программ. При одновременном выполнении двух и более апплетов приобретают актуальность вопросы управления ресурсами и защиты, которые должны быть решены с помощью имеющейся на карте операционной системы (как правило, весьма примитивной).

![[Pasted image 20251025143926.png]]

---
# Сети передачи информации
Теперь мы понимаем как устроены цифровые устройства. Пора объединить одиночные устройства в одну цифровую экосистему. Без такой экосистемы не было бы ни Интернета, ни облачных технологий, ни потокового видео, ни социальных сетей.
## Первые компьютерные сети
Обратимся сначала к компьютерному корню вычислительных сетей. Первые компьютеры 1950-х годов – большие, громоздкие и дорогие – предназначались для очень небольшого числа избранных пользователей. Часто эти монстры занимали целые здания. Такие компьютеры не были предназначены для интерактивной работы пользователя, а применялись в **режиме пакетной обработки**.

**Системы пакетной обработки**, как правило, строились на базе мейнфрейма – мощного и надежного компьютера универсального назначения. Пользователи подготавливали перфокарты, содержащие данные и команды программ, и передавали их в вычислительный центр. Задания нескольких пользователей группировались в пакет, который принимался на выполнение. Оператор мейнфрейма вводил карты пакета в компьютер, который обрабатывал задания в многопрограммном режиме, оптимизируя распределение процессора и устройств ввода-вывода между заданиями для достижения максимальной производительности вычислений. Распечатанные результаты пользователи получали обычно только на следующий день. Таким образом, одна неверно набитая карта означала как минимум суточную задержку. Конечно, для пользователей интерактивный режим работы, при котором можно с терминала оперативно руководить процессом обработки своих данных, был бы удобнее. Но интересами пользователей на первых этапах развития вычислительных систем в значительной степени пренебрегали. Во главу угла ставилась эффективность работы самого дорогого устройства вычислительной машины – процессора, даже в ущерб эффективности работы использующих его специалистов.
![[Pasted image 20251016204953.png]]

По мере удешевления процессоров в начале 60-х годов появились новые способы организации вычислительного процесса, которые позволили учесть интересы пользователей. Начали развиваться интерактивные **многотерминальные системы разделения времени**. В таких системах каждый пользователь получал собственный терминал, с помощью которого он мог вести диалог с компьютером. Количество одновременно работающих с компьютером пользователей определялось его мощностью: время реакции вычислительной системы должно было быть достаточно мало, чтобы пользователю была не слишком заметна параллельная работа с компьютером других пользователей.
![[Pasted image 20251016205250.png]]
Терминалы, выйдя за пределы вычислительного центра, рассредоточились по всему предприятию. И хотя вычислительная мощность оставалась полностью централизованной, некоторые функции – такие как ввод и вывод данных – стали распределенными. Подобные многотерминальные централизованные системы внешне уже были очень похожи на локальные вычислительные сети. Действительно, рядовой пользователь работу за терминалом мейнфрейма воспринимал примерно так же, как сейчас он воспринимает работу за подключенным к сети персональным компьютером. Пользователь мог получить доступ к общим файлам и периферийным устройствам, при этом у него поддерживалась полная иллюзия единоличного владения компьютером, так как он мог запустить нужную ему программу в любой момент и почти сразу же получить результат (некоторые далекие от вычислительной техники пользователи даже были уверены, что все вычисления выполняются внутри их дисплея).

Однако до появления локальных сетей нужно было пройти еще большой путь, так как многотерминальные системы, хотя и имели внешние черты распределенных систем, все еще поддерживали централизованную обработку данных.

К тому же потребность предприятий в создании локальных сетей в это время еще не созрела – в одном здании просто нечего было объединять в сеть, так как из-за высокой стоимости вычислительной техники предприятия не могли себе позволить роскошь приобретения нескольких компьютеров. В этот период был справедлив так называемый **закон Гроша**, который эмпирически отражал достигнутый уровень технологии. В соответствии с этим законом *производительность компьютера была пропорциональна квадрату его стоимости*. Отсюда следовало, что за одну и ту же сумму было выгоднее купить одну мощную машину, чем две менее мощных – их суммарная мощность оказывалась намного ниже мощности дорогой машины.

## Первые глобальные сети
А вот потребность в соединении нескольких компьютеров, находящихся на большом расстоянии друг от друга, к этому времени уже вполне назрела. Началось все с решения более простой задачи – доступа к отдельному компьютеру с терминалов, удаленных от него на многие сотни, а то и тысячи километров. Терминалы соединялись с компьютером через телефонные сети с помощью модемов, позволив многочисленным пользователям получать удаленный доступ к разделяемым ресурсам мощных суперкомпьютеров. Затем появились системы, в которых наряду с удаленными соединениями типа *терминал – компьютер* были реализованы и удаленные связи типа *компьютер – компьютер*.

Разнесенные территориально компьютеры получили возможность *обмениваться данными в автоматическом режиме*, что, собственно, и является базовым признаком любой вычислительной сети.
На основе подобного механизма в первых сетях были реализованы службы обмена файлами, синхронизации баз данных, электронной почты и другие, ставшие теперь традиционными сетевые службы.

Итак, хронологически первыми появились **глобальные сети** (Wide Area Network, **WAN**), то есть сети, объединяющие территориально рассредоточенные компьютеры, возможно, находящиеся в различных городах и странах.

Именно при построении глобальных сетей были впервые предложены и отработаны многие основные идеи, лежащие в основе современных вычислительных сетей. Такие, например, как многоуровневое построение коммуникационных протоколов, концепции коммутации и маршрутизации пакетов.

Глобальные компьютерные сети очень многое унаследовали от других, гораздо более старых и распространенных глобальных сетей – *телефонных*. Главное технологическое новшество, которое привнесли с собой первые глобальные компьютерные сети, состояло в отказе от **принципа коммутации каналов**, на протяжении многих десятков лет успешно использовавшегося в телефонных сетях.

В 1969 году министерство обороны США инициировало работы по объединению в единую сеть суперкомпьютеров оборонных и научно-исследовательских центров. Эта сеть, получившая название ARPANET, стала отправной точкой для создания первой и самой известной ныне глобальной сети мирового масштаба – **Internet**.

Сеть ARPANET объединяла компьютеры разных типов, работавшие под управлением различных операционных систем (ОС) с дополнительными модулями, реализующими коммуникационные протоколы, общие для всех компьютеров сети. ОС этих компьютеров можно считать *первыми* **сетевыми операционными системами**.
Сетевые ОС позволили не только рассредоточить пользователей между несколькими компьютерами (как в многотерминальных системах), но и организовать распределенные хранение и обработку данных.

## Первые локальные сети
Важное событие, повлиявшее на эволюцию компьютерных сетей, произошло в начале 70-х годов. В результате технологического прорыва в области производства компьютерных компонентов появились **большие интегральные схемы** (БИС). Их сравнительно невысокая стоимость и хорошие функциональные возможности привели к созданию **мини-компьютеров**, которые стали реальными конкурентами мейнфреймов. Эмпирический закон Гроша перестал соответствовать действительности, так как десяток мини-компьютеров, имея ту же стоимость, что и один мейнфрейм, решали некоторые задачи (как правило, хорошо распараллеливаемые) быстрее.
Даже небольшие подразделения предприятий получили возможность иметь собственные компьютеры. Мини-компьютеры решали задачи управления технологическим оборудованием, складом и другие задачи уровня отдела предприятия. Таким образом, появилась концепция распределения компьютерных ресурсов по всему предприятию. Однако при этом все компьютеры одной организации по-прежнему продолжали работать *автономно*.
![[Pasted image 20251016210349.png]]

Шло время, потребности пользователей вычислительной техники росли. Их уже не удовлетворяла изолированная работа на собственном компьютере, им хотелось в автоматическом режиме обмениваться компьютерными данными с пользователями других подразделений. Ответом на эту потребность и стало появление первых локальных вычислительных сетей.
![[Pasted image 20251016210457.png]]
**Локальные сети** (Local Area Network, **LAN**) – это объединения компьютеров, сосредоточенных на небольшой территории, обычно в радиусе не более 1–2 км, хотя в отдельных случаях локальная сеть может иметь и большие размеры, например, несколько десятков километров. Обычно локальная сеть представляет собой коммуникационную систему, принадлежащую одной организации.
На первых порах для соединения компьютеров друг с другом использовались *нестандартные* сетевые технологии.

**Сетевая технология** – это согласованный набор программных и аппаратных средств (например, драйверов, сетевых адаптеров, кабелей и разъемов), а также механизмов передачи данных по линиям связи, достаточный для построения вычислительной сети.

Разнообразные устройства сопряжения, использующие собственные способы представления данных на линиях связи, свои типы кабелей и т. п., могли соединять только те конкретные модели компьютеров, для которых были разработаны, например, мини-компьютеры PDP-11 с мейнфреймом IBM 360 или мини-компьютеры HP с микрокомпьютерами LSI-11. Такая ситуация создала большой простор для творчества студентов – названия многих курсовых и дипломных проектов начинались тогда со слов «Устройство сопряжения…».

Мощным стимулом для их появления послужили **персональные компьютеры**. Эти массовые продукты стали идеальными элементами построения сетей – с одной стороны, они были достаточно мощными, чтобы обеспечивать работу сетевого программного обеспечения, а с другой – явно нуждались в объединении своей вычислительной мощности для решения сложных задач, а также разделения дорогих периферийных устройств и дисковых массивов. Поэтому персональные компьютеры стали преобладать в локальных сетях, причем не только в качестве клиентских компьютеров, но и в качестве центров хранения и обработки данных, то есть сетевых серверов, потеснив с этих привычных ролей миникомпьютеры и мейнфреймы.
Стандартные сетевые технологии превратили процесс построения локальной сети из решения нетривиальной технической проблемы в рутинную работу. Для создания сети достаточно было приобрести стандартный кабель, сетевые адаптеры соответствующего стандарта, например Ethernet, вставить адаптеры в компьютеры, присоединить их к кабелю стандартными разъемами и установить на компьютеры одну из популярных сетевых операционных систем, например Novell NetWare.

Разработчики локальных сетей привнесли много нового в организацию работы пользователей. Так, стало намного проще и удобнее, чем в глобальных сетях, получать доступ к общим сетевым ресурсам. Последствием и одновременно движущей силой такого прогресса стало появление огромного числа непрофессиональных пользователей, освобожденных от необходимости изучать специальные (и достаточно сложные) команды для сетевой работы.
Конец 90-х выявил явного лидера среди технологий локальных сетей – семейство **Ethernet**, в которое вошли классическая технология **Ethernet** со скоростью передачи 10 Мбит/c, а также **Fast Ethernet** со скоростью 100 Мбит/c и **Gigabit Ethernet** со скоростью 1000 Мбит/c.

Долгие годы Ethernet была технологией только локальных сетей, однако, дополненная новыми функциями и новыми уровнями скоростей, эта технология сегодня преобладает на линиях связи и глобальных сетей. Следствием доминирования технологии **Ethernet** в первом десятилетии XXI века стало упрощение структуры как локальных, так и глобальных сетей – в подавляющем большинстве подсетей сегодня работает протокол **Ethernet**, а объединяются подсети в составную сеть с помощью протокола **IP**.

Еще одним признаком сближения локальных и глобальных сетей является появление сетей, занимающих промежуточное положение между локальными и глобальными сетями. **Городские сети**, или **сети мегаполисов** (Metropolitan Area Network, **MAN**), предназначены для обслуживания территории крупного города.
Эти сети используют цифровые линии связи, часто оптоволоконные, со скоростями на магистрали 10 Гбит/с и выше. Они обеспечивают экономичное соединение локальных сетей между собой, а также выход в глобальные сети. Сети MAN первоначально были разработаны только для передачи данных, но сейчас перечень предоставляемых ими услуг расширился, в частности, они поддерживают видеоконференции и интегральную передачу голоса и текста. Современные сети MAN отличаются разнообразием предоставляемых услуг, позволяя своим клиентам объединять коммуникационное оборудование различного типа.
## Интернет как фактор развития сетевых технологий
Интернет является вершиной эволюции телекоммуникационных сетей, самой быстрорастущей технической системой в истории человечества. Интернет растет и качественно развивается постоянно, начиная с 80-х годов, и в соответствии с прогнозами специалистов этот процесс будет продолжаться.
«Размеры» Интернета можно оценивать по-разному, чаще всего используют такие показатели, как количество подключенных к Интернету терминальных устройств, количество пользователей, объем трафика, передаваемый в единицу времени.
Качественное развитие Интернета проявляется в появлении все новых и новых сервисов, например, уже упомянутых интернет-вариантов телефонии и телевидения, а также новых типов терминальных устройств. Так, помимо «чистых» компьютеров к Интернету стали подключаться разнообразные устройства со встроенными «компьютерами» – смартфоны, планшеты, бытовые приборы, автомобили, и этот список можно продолжать еще долго.

Рассмотрим сначала в цифрах количественный рост Интернета.
На показан график роста числа пользователей Интернета за 50 лет существования этой сети. В начале 2019 года их число составило 4,388 миллиарда, то есть 57 % населения земного шара.
![[Pasted image 20251016211435.png]]
Количество терминальных устройств, выполняющих функции серверов (без учета пользовательских устройств) росло примерно такими же темпами: в 1980 году насчитывалось около 1000 хостов, подключенных к Интернету, в 1991-м – более 1 000 000, в начале 2000-х – около 100 000 000 и, наконец, в 2018 году – свыше 1 миллиарда. С учетом пользовательских устройств (настольных компьютеров, ноутбуков, планшетов и мобильных телефонов) общее количество терминальных устройств, подключенных к Интернету, составило в 2018 году около 23 миллиардов.

Абсолютно взрывным оказался рост объема трафика (количество байтов, переданных в месяц через магистрали Интернета):
- 1990 год: 1 терабайт (ТБ);
- 1996 год: 2000 ТБ;
- 2000 год: 84 петабайта (ПБ);
- 2008 год: 10 экзабайт (ЭБ);
- 2013 год: 50 ЭБ;
- 2018 год: 129 ЭБ.
В середине 90-х трафик рос особенно быстро, удваиваясь каждый год, то есть демонстрируя экспоненциальный рост. Затем рост несколько замедлился, но все равно за последние 5 лет объем передаваемого трафика вырос в 2,6 раза.

Очевидно, что Интернет не рос бы так быстро, если бы он не изменялся качественно и оставался все это время только средством передачи файлов и обмена текстовыми сообщениями электронной почты. Новые сервисы и новые типы терминальных устройств делали и делают Интернет привлекательным для все большего числа массовых пользователей, которым раньше вряд ли пришло бы в голову использовать компьютер в повседневной жизни.

Если мы посмотрим на терминальные интернет-устройства, то увидим, что сегодня большую их часть составляют не традиционные персональные настольные компьютеры, а мобильные устройства – планшеты и смартфоны. В результате, если в 2013 году больше половины интернет-трафика (67 %) генерировали персональные компьютеры, то в 2018 году они уступили пальму первенства мобильным устройствам и встроенным компьютерам, в совокупности сгенерировавшим 53 % трафика.

Существенно менялся и процентный состав приложений, генерирующих трафик. Так, если в 90-е годы и начале 2000-х в общем объеме преобладал трафик приложений, передающих файлы (файлы электронной почты, веб-страниц, музыки и кинофильмов), то уже к 2010 году он уступил лидерство трафику приложений, передающих видеопотоки в реальном масштабе времени (таких как интернет-телевидение, показ кинофильмов в онлайновом режиме по требованию, видеоконференции).

Новой вехой на пути развития Интернета стали облачные вычисления, которые позволяют разгрузить пользовательский компьютер и перенести хранение данных и выполнение приложений на некоторые удаленные компьютеры, связанные с пользовательским компьютером через сеть. Облачные вычисления стали еще одной причиной увеличения трафика Интернета, так как пользователи этого сервиса постоянно обращаются к внешним серверам провайдера, вместо того чтобы производить вычисления и другие манипуляции с данными локально, на своих персональных компьютерах или на корпоративных серверах.
## Физическая передача данных по линиям связи
Даже при рассмотрении простейшей сети, состоящей всего из двух машин, можно выявить многие проблемы, связанные с физической передачей сигналов по линиям связи.
В вычислительной технике для представления данных используется **двоичный код**. Внутри компьютера единицам и нулям данных соответствуют дискретные электрические сигналы.
Представление данных в виде электрических или оптических сигналов называется **кодированием**.

Существуют различные способы кодирования двоичных цифр, например, **потенциальный способ**, при котором единице соответствует один уровень напряжения, а нулю – другой, или **импульсный способ**, когда для представления цифр используются импульсы различной полярности.
В вычислительных сетях применяют как потенциальное, так и импульсное кодирование дискретных данных, а также специфический способ представления данных, который никогда не используется внутри компьютера, – **модуляцию** . При модуляции дискретная информация представляется синусоидальным сигналом той частоты, которую хорошо передает имеющаяся линия связи.
![[Pasted image 20251016213048.png]]
Для повышения надежности передачи данных между компьютерами, как правило, используется стандартный прием – подсчет **контрольной суммы** и передача полученного значения по линиям связи после каждого байта или после некоторого блока байтов. Часто в протокол обмена данными включается как обязательный элемент **сигнал-квитанция**, который подтверждает правильность приема данных и посылается от получателя отправителю.

Физические каналы связи делятся на несколько типов в зависимости от того, могут они передавать информацию в обоих направлениях или нет.
- **Дуплексный канал** обеспечивает одновременную передачу информации в обоих направлениях. Дуплексный канал может состоять из двух физических сред, каждая из которых используется для передачи информации только в одном направлении. Возможен вариант, когда одна среда служит для одновременной передачи встречных потоков. При этом применяют дополнительные методы выделения каждого потока из суммарного сигнала.
- **Полудуплексный канал** обеспечивает передачу информации в обоих направлениях, но не одновременно, а по очереди. То есть в течение определенного периода времени информация передается в одном направлении, а в течение следующего периода – в обратном.
- **Симплексный канал** позволяет передавать информацию только в одном направлении. Часто дуплексный канал состоит из двух симплексных каналов.

В качестве среды передачи в большинстве сетей применяют три группы кабелей: коаксиальный кабель, витая пара, оптоволоконный кабель. 
Простой *коаксиальный кабель* состоит из медной жилы, окружающей её изоляции, экрана в виде металлической оплётки и внешней оболочки. Снаружи кабель покрыт непроводящим слоем из резины, тефлона или пластика.
Согласно современным стандартам, коаксиальный кабель не считается хорошим выбором при построении структурированной кабельной системы зданий. Перечислим основные типы и характеристики этих кабелей.
- **«Толстый» коаксиальный кабель** разработан для сетей Ethernet 10Base-5 с волновым сопротивлением 50 Ом и внешним диаметром около 12 мм. Этот кабель имеет достаточно толстый внутренний проводник диаметром 2,17 мм, который обеспечивает хорошие механические и электрические характеристики (затухание на частоте 10 МГц – не хуже 18 дБ/км). Однако этот кабель сложно монтировать – он плохо гнется.
- **«Тонкий» коаксиальный кабель** предназначен для сетей Ethernet 10Base-2. Обладая внешним диаметром около 5 мм и тонким внутренним проводником 0,89 мм, этот кабель не так прочен, как «толстый» коаксиал, зато обладает гораздо большей гибкостью, что удобно при монтаже. «Тонкий» коаксиальный кабель также имеет волновое сопротивление 50 Ом, но его механические и электрические характеристики хуже, чем у «толстого» коаксиального кабеля. Затухание в этом типе кабеля выше, чем в «толстом» коаксиальном кабеле, что приводит к необходимости уменьшать длину кабеля для получения одинакового затухания в сегменте.
- **Телевизионный кабель** с волновым сопротивлением 75 Ом широко применяется в кабельном телевидении. Существуют стандарты локальных сетей, позволяющие использовать такой кабель для передачи данных.
- **Твинаксиальный кабель** по конструкции похож на коаксиальный кабель, но отличается наличием двух внутренних проводников. Такой кабель применяется в новых высокоскоростных стандартах 10G и 100G Ethernet для передачи данных на небольшие расстояния – распараллеливание потоков данных между двумя проводниками упрощает достижение высокой суммарной скорости.

Простая *витая пара* – представляет собой одну или несколько пар изолированных медных проводов, скрученных между собой. Несколько витых пар часто помещают в одну защитную оболочку. Их количество в кабеле может быть различно (1, 8, 16...).
Кабель на основе витой пары, используемый для проводки внутри здания, разделяется в международных стандартах на категории (от 1 до 8). Кабели категорий **1**, **2**, **3** и **4** сегодня практически не применяются.
Кабели категории **5** были специально разработаны для поддержки высокоскоростных протоколов. Их характеристики определяются в диапазоне до 100 МГц. Существует улучшенная версия категории **5e** (5 enhanced), которая была разработана специально для более качественной поддержки протокола Gigabit Ethernet в основном за счет более жестких ограничений на перекрестные наводки.
Появление технологии 10G Ethernet привело к стандартизации более качественных кабелей категорий **6**, **6a**, **7** и **8**. Для кабеля категории **6** характеристики определяются до частоты 250 МГц, категории **6a** – до 500 МГц, а для кабелей категории **7** – до 600 МГц.
Кабели категории **7** обязательно экранируются, причем как каждая пара, так и весь кабель в целом. Кабель категории **6** может быть как экранированным, так и неэкранированным. Максимальная длина сегмента 10G Ethernet на кабеле категории **6** равна 55 м, а на кабелях категорий **6а** и **7** – 100 м. Для кабелей категории **8** характеристики определяются до частоты 2000 МГц и расстояния кабеля до 30 м

В *оптоволоконном кабеле* цифровые данные распространяются по оптическим волокнам в виде модулированных световых импульсов. Оптоволоконные линии предназначены для передачи больших объёмов данных на очень высоких скоростях до нескольких десятков гигабит в секунду, т.к. сигналы в них практически не затухают и не искажаются.
Волоконно-оптический кабель состоит из тонких (5–60 микрон) гибких стеклянных волокон (волоконных световодов), по которым распространяются световые сигналы. Это наиболее качественный тип кабеля – он обеспечивает передачу данных с очень высокой скоростью (до 100 Гбит/с и выше) на большие расстояния (80–100 км без промежуточного усиления), к тому же он лучше других типов передающей среды обеспечивает защиту данных от внешних помех (в силу особенностей распространения света такие сигналы легко экранировать).
Каждый световод состоит из центрального проводника света (*сердечника*, или *сердцевины*) – стеклянного волокна и стеклянной оболочки, обладающей меньшим показателем преломления, чем сердцевина. Распространяясь по сердцевине, лучи света не выходят за ее пределы, отражаясь от покрывающего слоя оболочки, так как она имеет более низкий коэффициент преломления. В зависимости от распределения показателя преломления и величины диаметра сердечника различают:
- многомодовое волокно со ступенчатым изменением показателя преломления (рис. а);
- многомодовое волокно с плавным изменением показателя преломления (рис. б);
- одномодовое волокно (рис. в).

![[Pasted image 20251016220156.png]]
Понятие «мода» описывает режим распространения световых лучей в сердцевине кабеля.
В **одномодовом кабеле** (Single Mode Fiber, **SMF**) используется центральный проводник очень малого диаметра, соизмеримого с длиной волны света – от 5 до 10 мкм. При этом практически все лучи света распространяются вдоль оптической оси световода, не отражаясь от внешнего проводника. Изготовление сверхтонких качественных волокон для одномодового кабеля представляет собой сложный технологический процесс, что делает одномодовый кабель достаточно дорогим. Кроме того, в волокно такого маленького диаметра трудно направить пучок света, не потеряв при этом значительную часть его энергии. Одномодовый кабель обладает очень *низким затуханием* – примерно –0,2 дБ/км для окна прозрачности волны размером в 1550 нм.
В **многомодовых кабелях** (Multi Mode Fiber, **MMF**) используются более широкие внутренние сердечники, которые легче изготовить технологически. В многомодовых кабелях во внутреннем проводнике одновременно существует несколько световых лучей, отражающихся от внешнего проводника под разными углами. Угол отражения луча называется **модой** луча. В многомодовых кабелях с плавным изменением коэффициента преломления режим отражения лучей имеет сложный характер. Возникающая при этом интерференция ухудшает качество передаваемого сигнала, что приводит к искажениям передаваемых импульсов. По этой причине технические характеристики многомодовых кабелей хуже, чем одномодовых.
Учитывая это, многомодовые кабели применяют в основном для передачи данных на скоростях не более 10 Гбит/с на небольшие расстояния (до 300–2000 м), а одномодовые – для передачи данных со сверхвысокими скоростями до сотен гигабитов в секунду (при использовании технологии **DWDM** (Dense Wave Division Multiplexing)
– до нескольких терабитов в секунду) на расстояния до нескольких десятков и даже сотен километров (дальняя связь).

`а как же беспроводные среды?`
Для передачи сообщений пригодны не только проводные каналы связи в виде воздушных линий, кабелей и др., но и радиоканалы. 
В соответствии с Международным регламентом радиосвязи, все радиоволны разделены на девять диапазонов с номерами от 4 до 12. Эти области радиочастот разделены границами (0,3...3,0) * $10^N$ Гц, где N – номер диапазона:
- **Диапазон 4:** Мириаметровые (сверхдлинные) волны (СДВ) с длиной волны 10–100 км, что соответствует очень низким частотам (ОНЧ) от 3 до 30 кГц.
- **Диапазон 5:** Километровые (длинные) волны (ДВ) с длиной волны 1–10 км, что соответствует низким частотам (НЧ) от 30 до 300 кГц.
- **Диапазон 6:** Гектометровые (средние) волны (СВ) с длиной волны 100–1000 м, что соответствует средним частотам (СЧ) от 300 до 3000 кГц.
- **Диапазон 7:** Декаметровые (короткие) волны (КВ) с длиной волны 10–100 м, что соответствует высоким частотам (ВЧ) от 3 до 30 МГц.
- **Диапазон 8:** Метровые или ультракороткие волны (УКВ) с длиной волны от 1 до 10 м. Соответствуют очень высоким частотам (ОВЧ) от 30 до 300 МГц.
- **Диапазон 9:** Дециметровые волны (ДМВ) с длиной волны от 10 до 100 см. Соответствуют ультравысоким частотам (УВЧ) от 300 до 3000 МГц.
- **Диапазон 10:** Сантиметровые волны с длиной волны от 1 до 10 см. Соответствуют сверхвысоким частотам (СВЧ) от 3 до 30 ГГц.
- **Диапазон 11:** Миллиметровые волны с длиной волны от 1 до 10 мм. Соответствуют крайне высоким частотам (КВЧ) от 30 до 300 ГГц.
- **Диапазон 12:** Децимиллиметровые волны с длиной волны от 0,1 до 1 мм. Соответствуют гипервысоким частотам (ГВЧ) от 300 до 3000 ГГц.
## Принципы передачи данных
Компьютерные сети, называемые также сетями передачи данных, являются логическим результатом эволюции двух важнейших научно-технических отраслей современной цивилизации – компьютерных и телекоммуникационных технологий.
Компьютерная сеть – это совокупность вычислительных систем, объединённых каналами передачи информации для её распространения и использования.
Самая простая сеть состоит из двух компьютеров, соединённых друг с другом кабелем, что позволяет им обмениваться данными. Рождение компьютерных сетей было обусловлено практической потребностью в совместном использовании данных. Концепция соединённых и совместно использующих ресурсы компьютеров называется сетевым взаимодействием.
Первоначально компьютерные сети были небольшими и объединяли до 10 компьютеров и один принтер. В начале 80-х годов самой популярной была сеть до 30 компьютеров с общей длиной кабеля до 200 метров. Эти сети располагались в пределах одного этажа здания или небольшой фирмы, поэтому они получили название локальных вычислительных сетей (ЛВС). Локальную сеть характеризуют высокая скорость и надежность передачи, эффективные механизмы управления обменом данными, ограниченное число компьютеров в сети.
Глобальные вычислительные сети (ГВС) рассчитаны на неограниченное число сетевых абонентов (включая ЛВС) и не имеют территориальных ограничений. Глобальные сети уступают локальным сетям по скорости и надежности передачи, по эффективности управления обменом данными. Главным для глобальной сети является факт существования связи на неограниченном расстоянии.

Термин компоновка или топология сети обозначает физическое расположение компьютеров, кабелей и других сетевых компонентов. От топологии зависит характеристика сети. Выбор топологии влияет на состав и возможности сетевого оборудования, возможности расширения сети и на способ управления сетью.
Все сети строятся на основе трёх базовых топологий: *шина* (bus), *звезда* (star) и *кольцо* (ring).
В топологии шина используется один кабель, называемый магистралью или сегментом, к которому подключены все компьютерные сети. Это самая простая и поначалу была самая распространённая реализация сети. Данные в виде электрических сигналов передаются всем компьютерам сети. Информацию получает тот компьютер, чей адрес закодирован в этих сигналах. Производительность этой сети зависит от количества компьютеров, подключённых к шине. Чем больше компьютеров, тем большее их число ожидает передачи, тем медленнее сеть. Передачу может вести только один компьютер.
![[Pasted image 20251011213839.png]]
При топологии звезда все компьютеры с помощью сегментов кабеля подключаются к центральному компоненту – концентратору (hub). Сигналы от передающего компьютера поступают через концентратор ко всем остальным. Недостатки этой топологии: для больших сетей значительно увеличивается расход кабеля; если концентратор выйдет из строя, остановится вся сеть.
![[Pasted image 20251011214107.png]]
При топологии кольцо все компоненты подключаются к кабелю, замкнутому в кольцо. Сигналы передаются по кольцу в одном направлении и проходят через каждый компьютер. Каждый компьютер выступает в роли повторителя, усиливая сигналы (это активная топология, как и звезда). Недостаток: если выходит из строя один компьютер, прекращает работу вся сеть.
![[Pasted image 20251011214158.png]]
Комбинированные топологии:
- звезда-шина;
![[Pasted image 20251011214309.png]]
- звезда-кольцо;
![[Pasted image 20251011214346.png]]
- полносвязная топология.
![[Pasted image 20251011214401.png]]

## Сетевые модели и протоколы
 В процессе передачи данных от одного компьютера к другому можно выделить следующие задачи:
- распознать данные;
- разбить данные на управляемые блоки;
- добавить информацию к каждому блоку, чтобы указать местонахождение данных и получателя;
- добавить информацию синхронизации и проверки ошибок;
- поместить данные в сеть и отправить по адресу.
### Модель OSI
В 1978 году организация ISO выпустила ряд спецификаций, описывающих архитектуру сети с неоднородными свойствами. Исходный документ относится к открытым системам, чтобы все они могли использовать одинаковые протоколы и стандарты для обмена информацией. В 1984г. ISO выпустила новую версию своей модели: «эталонная модель взаимодействия открытых систем» – Open System Interconnection (OSI). Она стала международным стандартом, и её спецификации используют производители при разработке сетевых продуктов. Являясь многоуровневой системой, она отражает взаимодействие аппаратного и программного обеспечения при осуществлении сеанса связи. В модели OSI все функции распределены по семи уровням.
![[Pasted image 20251016214106.png]]
Нижние уровни определяют физическую связь передачи данных и соответствующие задачи. Верхние уровни определяют, каким образом осуществляется доступ приложений к услугам связи. Уровни отделяются границами – интерфейсами.
Перед передачей в сеть данные разбиваются на пакеты. **Пакет** – единица информации, передаваемая между устройствами сети как единое целое. Пакеты проходят последовательно через все уровни программного обеспечения. На каждом уровне к пакету добавляется некоторая информация – формирующая или адресная, которая необходима для успешной передачи данных по сети. На принимающей стороне пакет проходит все уровни в обратном порядке. Программное обеспечение читает информацию пакета, затем удаляет информацию, добавленную пакету на этом же уровне отправителя, и передаёт информацию следующему уровню. Когда пакет дойдёт до прикладного уровня, вся адресная информация будет удалена, и данные примут первоначальный вид. За исключением нижнего уровня сетевой модели никакой другой уровень не может послать информацию соответствующему уровню приёмника.
**Прикладной уровень** – это интерфейс для доступа к сетевым услугам, который поддерживает приложения пользователей, такие как доступ к базам данных, передача файлов и электронная почта. Он также управляет общим доступом к сети и восстановлением данных после сбоев.
**Представительский уровень** – определяет формат обмена данными между компьютерами. Он отвечает за преобразование протоколов, шифрование данных, преобразование кодировки и сжатие данных.
**Сеансовый уровень** позволяет двум приложениям, установленным на разных компьютерах, начинать, использовать, завершать соединения, называемые сеансом. На данном уровне выполняется распознавание имён и защита, необходимые для связи двух приложений. Сеансовый уровень обеспечивает синхронизацию между пользовательским задачами посредством расстановки в потоке данных контрольных точек.
**Транспортный уровень** гарантирует доставку пакетов без ошибок в той же последовательности без потерь и дублирования. На этом уровне компьютера-отправителя данные переупаковываются: длинные разбиваются на несколько пакетов, а короткие объединяются в один. Это повышает эффективность передачи пакетов по сети. На транспортном уровне получателя сообщение распаковывается и обычно посылается сигнал подтверждения приёма.
**Сетевой уровень** отвечает за адресацию сообщений и перевод логических адресов и имён в физические адреса. Здесь определяется маршрут от компьютера-отправителя к компьютеру-получателю; решаются задачи, связанные с сетевым трафиком, такие, как коммутация пакетов, маршрутизация и перегрузки. Если сетевой адаптер маршрутизатора не может передавать большие блоки данных, посланных отправителем на сетевом уровне, эти блоки разбиваются на меньшие.
**Канальный уровень** осуществляет передачу кадров данных от сетевого уровня к физическому. Кадр – логически организованная структура, в которую можно помещать данные. Канальный уровень компьютера-получателя упаковывает «сырой» поток битов, поступающих от физического уровня в кадры данных. Он обеспечивает точность передачи данных между двумя компьютерами через физический уровень.
**Физический уровень** осуществляет передачу неструктурированного («сырого») потока битов по физической среде. Здесь реализуется электрический, оптический, механический и функциональный интерфейсы с кабелем. Физический уровень формирует служебные сигналы, которые переносят данные, поступившие от вышележащего уровня. Содержание самих битов на данном уровне значения не имеет. Этот уровень отвечает за кодирование данных и синхронизацию битов, гарантируя, что переданная единица будет воспринята как единица, а не как ноль.
### Модель Project 802
Проект Project 802 выпущен в феврале 1980 года, был разработан в Институте инженеров по электротехнике и электронике – IEEE (англ. Institute of Electrical and Electronics Engineers).
Project 802 устанавливает стандарты для физических компонентов сети, интерфейсных плат и кабельных систем, с которыми связаны физические и канальные уровни OSI. Стандарты, называемые 802-спецификациями, распространяются на платы сетевых адаптеров, компоненты глобальных вычислительных сетей и компоненты сетей, использующих кабели. Например, *802.3* – локальная вычислительная сеть архитектуры Ethernet; *802.4* – ЛВС топологии шина с=передачей маркера; *802.10* – безопасность сетей.
Project 802, подробно описывая канальный уровень, разделил его на два подуровня:
- **Управление логической связью (LLC):** отвечает за установление и разрыв соединения, управление потоком данных, упорядочивание и подтверждение приёма кадров.
- **Управление доступом к среде (MAC):** отвечает за определение границ кадров, контроль ошибок и распознавание адресов кадров.
**Протокол** – это набор правил и процедур, регулирующий порядок осуществления некоторой связи. **Сетевые протоколы** – правила и технические процедуры, позволяющие нескольким компьютерам при объединении в сеть общаться друг с другом.
Основные особенности:
- каждый протокол имеет свои цели, выполняет конкретные задачи, обладает своими преимуществами и ограничениями;
- протоколы работают на разных уровнях OSI. Функции протоколов определяются уровнем, на которых он работает;
- несколько протоколов могут работать совместно. В этом случае они образуют стек или набор протоколов.
Данные, передаваемые из одной локальной сети в другую по одному из возможных маршрутов, называются маршрутизированными. Протоколы, поддерживающие передачу данных между сетями по нескольким маршрутам, называются маршрутизируемыми. Каждый уровень стека протоколов определяет различные протоколы для управления функциями связи.
В качестве стандартных моделей протоколов разработано несколько моделей стеков: OSI, Novell Netware; набор протоколов Интернета TCP/IP, протоколы фирмы IBM. Протоколы этих стеков выполняют специфическую для своего уровня работу. Коммуникационные задачи, которые возложены на сеть, позволяют выделить среди протоколов три типа: прикладные, транспортные и сетевые.

*Прикладные протоколы* работают на трех верхних уровнях модели OSI, обеспечивают взаимодействие приложений и обмен данными между ними. Наиболее популярные прикладные протоколы:
- **HTTP/HTTPS** (Hypertext Transfer Protocol / Secure) – протоколы для передачи гипертекста, используемые для доступа к веб-страницам.
- **SMTP** (Simple Mail Transfer Protocol) – протокол, используемый для обмена электронной почтой.
- **FTP** (File Transfer Protocol) – протокол для передачи файлов.
- **SNMP** (Simple Network Management Protocol) – протокол для мониторинга сети и сетевых устройств.
- **Telnet** – протокол для регистрации удаленных хостов и обработки данных на них.
- **X.400** – протокол для международного обмена электронной почтой.
- **X.500** – протокол службы файлов и каталогов.
- **DNS** (Domain Name System) – протокол, преобразующий доменные имена в IP-адреса. 
- **SSH** (Secure Shell) – протокол для безопасного удаленного управления операционной системой.
*Транспортные протоколы* – поддерживают сеанс связи между ПК и гарантируют надёжный обмен данными:
- **TCP (Transmission Control Protocol)** – протокол, обеспечивающий гарантированную доставку данных, разбитых на пакеты.
- **SPX (Sequenced Packet Exchange)** – протокол, разработанный компанией Novell.
- **UDP (User Datagram Protocol)** – протокол пользовательских дейтаграмм стека TCP/IP.
- **SCTP (Stream Control Transmission Protocol)** – протокол, который сочетает в себе надёжность TCP и скорость UDP, обеспечивая гарантированную доставку данных и поддержку нескольких потоков в одном соединении.
*Сетевые протоколы* – обеспечивают услуги связи, имеют дело с адресной и маршрутной информацией:
- **IP (Internet Protocol)** – это сетевой протокол стека TCP/IP, который отвечает за адресацию и маршрутизацию данных в сети. 
- **IPX (Internetwork Packet Exchange)** – это маршрутизируемый протокол, который использовался в операционной системе NetWare компании Novell.
- **ICMP** (Internet Control Message Protocol) – используется для диагностики и передачи сообщений об ошибках в сети.
- **ARP** (Address Resolution Protocol) – преобразует IP-адреса в физические MAC-адреса.
## Распределение протоколов по элементам сети
На рисунке показаны основные элементы компьютерной сети: конечные узлы – компьютеры; промежуточные узлы – коммутаторы и маршрутизаторы.
![[Pasted image 20251016214846.png]]
Из рисунка видно, что полный стек протоколов реализован только на конечных узлах, а коммуникационным устройствам для продвижения пакетов достаточно функциональности нижних трех уровней. Более того, коммуникационное устройство может поддерживать только протоколы двух нижних уровней или даже одного физического уровня – это зависит от типа устройства.
Именно к таким устройствам, работающим на физическом уровне, относятся, например, сетевые *повторители*, называемые также *концентраторами* или *хабами*. Они повторяют электрические сигналы, поступающие на одни их интерфейсы, на других своих интерфейсах, улучшая характеристики сигналов – мощность и форму, синхронность их следования.
*Коммутаторы локальных сетей* поддерживают протоколы двух нижних уровней, физического и канального, что дает им возможность работать в пределах стандартных топологий.
*Маршрутизаторы* должны поддерживать протоколы всех трех уровней, так как сетевой уровень нужен им для объединения сетей различных технологий, а протоколы нижних уровней – для взаимодействия с конкретными сетями, образующими составную сеть, например, Ethernet или Frame Relay.
*Коммутаторы глобальных сетей*, работающие на основе технологии виртуальных каналов, могут поддерживать как два уровня протоколов, так и три.

---
# Хранение информации
## Технологии хранения информации
Хранение является одной из основных операций, осуществляемых над информацией, с целью обеспечения ее доступности в течение некоторого промежутка времени.
Под **хранением** понимают ее запись в запоминающее устройство для последующего использования.
Таким образом вся информация хранится в **памяти** компьютера – запоминающем устройстве, предназначенном для хранения исходной, промежуточной и конечной информации, а также программ по ее обработке.

Прежде чем погрузиться в конкретные технологии, важно понять базовый принцип организации памяти в любой вычислительной системе – **иерархию памяти**. Эта пирамида выстроена на компромиссе между тремя ключевыми параметрами: скоростью доступа, стоимостью хранения и объемом.

**Регистровая память** в составе процессора предназначена для кратковременного хранения небольшого объема информации, непосредственно участвующей в вычислениях.
Следующий уровень – **кэш-память** разных уровней (L1, L2, L3). КЭШ-память – это высокоскоростная память сравнительно большой емкости является буфером между устройствами с различным быстродействием (микропроцессором и оперативной памятью). Использование КЭШ – памяти позволяет увеличить скорость выполнения операций. Регистры КЭШ-памяти недоступны для пользователя, отсюда и название КЭШ (“тайник” в переводе с английского). В КЭШ-памяти хранятся данные, которые будут использоваться в ближайшее время. Микропроцессоры, начиная с 486 и выше, имеют встроенную КЭШ-память.

**Основная память** предназначена для оперативного хранения информации и обмена данными, используемыми в процессе обработки. Делится ОС на ПЗУ и ОЗУ. **Постоянное запоминающее устройство (ПЗУ)** – служит для хранения неизменяемой (постоянной) информации, позволяет только считывать информацию. ПЗУ является основным и энергонезависимым, т.е. при отключении питания информация в ней сохраняется. **Оперативное запоминающее устройство (ОЗУ)** – служит для оперативной записи, хранения и считывания информации (программ и данных) в процессе ее обработки. ОЗУ – энергозависимая память, т.е. при отключении питания информация в ней теряется. Основу ОЗУ составляют большие интегральные схемы, содержащие матрицы полупроводниковых запоминающих элементов (триггеров). Конструктивно ОЗУ выполнено в виде отдельных микросхем, расположенных на материнской плате ПК.

Для решения проблемы с утратой данных при отключения питания были придуманы **устройствах долговременного хранения** или **внешнее запоминающее устройство (ВЗУ)**.
К внешним запоминающим устройствам (ВЗУ) относятся:
- Ленточные накопители (стримеры) – один из самых ранних видов, использовались с 1950-х годов.
- Накопители на жестких магнитных дисках (НЖМД - винчестер) – появились в 1956 году.
- Накопители на гибких магнитных дисках (НГМД - дискета) – первые дискеты были представлены в 1971 году.
- Магнитооптические носители (диски) информации – коммерческие образцы появились в середине 1980-х годов.
- Накопители на оптических дисках (CD, DVD) – CD-ROM появились в 1985 году, DVD – в 1996 году.
- Флеш-диски – первые коммерческие USB-флеш-накопители появились в 2000 году.

Одним из самых ранних видов ВЗУ стали *ленточные накопители*, или стримеры, которые использовались с 1950-х годов. Их принцип действия основан на последовательной записи данных на магнитную ленту, аналогичную той, что применялась в кассетных магнитофонах. Ключевым преимуществом стримеров была и остается чрезвычайно низкая стоимость хранения большого объема данных. Однако главный их недостаток – последовательный доступ к информации – делает их крайне медленными для повседневной работы, так как для поиска нужного файла приходится физически перематывать ленту. Именно поэтому стримеры нашли свою нишу в создании архивных резервных копий «холодных» данных, к которым обращаются редко, и используются в корпоративной среде до сих пор.

Настоящий прорыв в области произвольного доступа к данным совершили накопители на жестких магнитных дисках (*НЖМД*), известные как винчестеры. Впервые представленные компанией IBM в 1956 году, они использовали жесткие алюминиевые пластины, покрытые ферромагнитным слоем, и магнитные головки, которые, не касаясь поверхности, считывали и записывали информацию. Это обеспечило высокую скорость доступа к любому участку диска. Благодаря оптимальному балансу стоимости, емкости и скорости винчестеры на десятилетия стали основным массовым хранилищем данных для персональных компьютеров и серверов, постоянно увеличивая свою емкость при уменьшении физических размеров.

Параллельно с винчестерами для переноса данных между компьютерами широко использовались накопители на гибких магнитных дисках (*НГМД*), или дискеты. Пройдя эволюцию от 8-дюймовых до самых популярных 3.5-дюймовых, дискеты с их скромной емкостью в 1.44 МБ стали символом эпохи ранних ПК. Они были дешевы, портативны и универсальны, что сделало их стандартом для распространения программного обеспечения и обмена файлами. Однако их низкая надежность, чувствительность к магнитным полям и механическим повреждениям, а также мизерный объем в конечном итоге привели к их исчезновению.

Стремление совместить емкость жестких дисков с надежностью переносных носителей привело к появлению в середине 1980-х годов *магнитооптических дисков*. В этой гибридной технологии для записи данных использовался лазер, который нагревал участок диска, и магнитная головка, которая меняла его намагниченность. Это делало носители чрезвычайно надежными и устойчивыми к случайному стиранию. Несмотря на высокую стоимость и относительно невысокую скорость записи, магнитооптические накопители заняли прочную позицию в профессиональной сфере, такой как полиграфия, дизайн и системы резервного копирования, где была критически важна сохранность данных.

Следующей революцией стали накопители на оптических дисках. Компакт-диски (*CD-ROM*), появившиеся в 1985 году, а затем и DVD (с 1996 года), кардинально изменили индустрию распространения контента. Используя лазер для считывания информации с поликарбонатной подложки, эти носители предлагали неслыханные для своего времени объемы – 700 МБ у CD и до 4.7 ГБ у однослойного DVD. Они были дешевы в массовом производстве, долговечны и портативны, что позволило им на два десятилетия стать основным каналом дистрибуции программного обеспечения, музыки, фильмов и компьютерных игр.

Венец этой эволюции – появление в 2000 году флеш-дисков, или *USB-накопителей*. Основанные на полупроводниковой флеш-памяти, они не имели движущихся частей, что делало их устойчивыми к ударам и вибрации. Их компактность, высокая скорость работы, удобство использования (достаточно воткнуть в USB-порт) и постоянно растущая емкость привели к тому, что они практически в одиночку вытеснили с рынка дискеты и сильно потеснили оптические диски. Флеш-накопители стали универсальным и самым распространенным в мире средством переноса цифровой информации, подведя итог многолетнему поиску идеального баланса между портативностью, надежностью и емкостью.

`А как же SSD и NVMe? К какому классу отнести их?`
**SSD** и **NVMe** – это не разные типы накопителей, а разные уровни технологии, и они относятся к одному и тому же современному типу: полупроводниковые (твердотельные) накопители.

**SSD (твердотельный накопитель)** – это обобщающее название для устройства хранения данных, в котором нет движущихся механических частей. Данные хранятся в микросхемах флеш-памяти (NAND).
- **Основная идея:** Замена медленным механическим жестким дискам (HDD).
- **Ключевая особенность:** Высокая скорость доступа, устойчивость к ударам, бесшумность.

**NVMe (Non-Volatile Memory Express)** – это современный протокол, специально разработанный для быстрой флеш-памяти. Он позволяет накопителю общаться с процессором напрямую, с минимальными задержками.

| Характеристика         | **SATA SSD**              | **NVMe SSD**                        |
| ---------------------- | ------------------------- | ----------------------------------- |
| **Тип накопителя**     | Твердотельный (SSD)       | Твердотельный (SSD)                 |
| **Протокол (логика)**  | AHCI (старый, для HDD)    | **NVMe** (новый, для SSD)           |
| **Интерфейс (физика)** | Разъем SATA               | Разъем **M.2** (чаще всего) или U.2 |
| **Шина данных**        | SATA III (до ~600 МБ/с)   | **PCI Express** (до ~8-16 ГБ/с)     |
| **Скорость**           | Высокая (ограничена SATA) | **Очень высокая / экстремальная**   |
| **Внешний вид**        | Коробочка 2.5 дюйма       | Небольшая планка ("стик")           |

**SSD** и **NVMe** относятся к одному типу – твердотельные накопители. **NVMe** – это не тип накопителя, а современный высокоскоростной протокол и стандарт для подключения **SSD**, которые пришли на смену устаревшей связке **SATA + AHCI**.

## Эволюция от локального к распределенному хранению
Но технологии хранения развиваются не только на физическом уровне. Не менее важна архитектура доступа к данным.
- **DAS (Direct Attached Storage):** Накопитель напрямую подключен к компьютеру (внутренний HDD/SSD, внешний диск по USB). Просто, но нет общего доступа.
- **NAS (Network Attached Storage):** Специализированное сетевое устройство, "файловый сервер". Предоставляет общее файловое пространство всем пользователям в локальной сети. Удобно для дома и малого офиса.
- **SAN (Storage Area Network):** Высокопроизводительная выделенная сеть, которая соединяет серверы с системами хранения на блочном уровне (как если бы диск был физически внутри сервера). Используется в крупных дата-центрах.
- **Облачное хранение (Cloud Storage):** Модель, при которой данные хранятся на удаленных серверах, управляемых провайдером (Яндекс.Диск, Google Drive, Dropbox). Доступ к ним осуществляется через Интернет.

Исторически первой была модель **DAS (Direct Attached Storage)**, когда накопитель физически подключен к компьютеру (внутренний диск или внешний по USB). Это просто, но не позволяет эффективно делиться данными.
Следующим шагом стало появление **NAS (Network Attached Storage)** – специализированного устройства, которое подключается к локальной сети и выступает в роли персонального «файлового сервера». Это идеальное решение для дома и малого офиса, позволяющее централизованно хранить данные и предоставлять к ним доступ всем пользователям сети.
В крупных дата-центрах используется более сложная и производительная архитектура – **SAN (Storage Area Network)**. Это выделенная высокоскоростная сеть, которая соединяет серверы с блочными системами хранения. Для сервера диск в SAN выглядит как локальный, что обеспечивает высочайшую производительность.
И, наконец, главный тренд последних десятилетий – **облачное хранение**. В этой модели данные физически находятся на удаленных серверах провайдера, а доступ к ним осуществляется через интернет. Преимущества облаков очевидны: доступность из любой точки мира, практически неограниченная и мгновенная масштабируемость, модель оплаты «по факту использования» и высочайшая надежность, обеспечиваемая избыточным копированием данных между разными дата-центрами. Однако есть и риски: это постоянная зависимость от канала связи и добросовестности провайдера, а также серьезные вопросы к безопасности и конфиденциальности данных, которые вы передаете в чужие руки.
## Вызовы современности и взгляд в будущее
Современные системы хранения информации сталкиваются с беспрецедентными вызовами, вызванными экспоненциальным ростом объемов данных и ужесточением требований к их обработке. Рассмотрим ключевые проблемы подробнее.
- **Информационный взрыв (Big Data):** Объем данных в мире растет экспоненциально. Требуются все более емкие и экономичные носители.
- **Энергоэффективность:** Крупные дата-центры потребляют гигантское количество энергии. Разрабатываются более экономичные системы хранения.
- **Долговременное сохранение (Data Degradation):** Цифровые носители имеют срок жизни. HDD выходят из строя, ячейки SSD со временем теряют заряд, оптические диски деградируют. Необходимы стратегии миграции данных и использование более стабильных сред.
- **Безопасность:** Защита данных от несанкционированного доступа, шифрование, создание отказоустойчивых систем (RAID-массивы, гео-репликация).

Ежедневно в мире создаются колоссальные объемы данных – от пользовательского контента в социальных сетях до телеметрии с IoT-устройств и научных исследований. По прогнозам, к 2025 году общий объем данных в мире может достичь 175 зеттабайт. Это создает несколько серьезных проблем:
- **Эффективное масштабирование** – традиционные архитектуры хранения не справляются с такими объемами.
- **"Холодные данные"** – до 80% информации после создания практически не используется, но должна сохраняться годами.
- **Стоимость владения** – включает не только закупку оборудования, но и энергопотребление, охлаждение и обслуживание.

Крупные дата-центры потребляют огромное количество энергии. Например, только на центры обработки данных приходится около 1% мирового потребления электроэнергии. Проблемы включают:
- **Энергоэффективность на терабайт** – поиск баланса между производительностью и энергопотреблением.
- **Тепловыделение** – необходимость сложных систем охлаждения, которые сами потребляют значительную энергию.
- **Углеродный след** – давление со стороны регуляторов и общества на сокращение environmental impact.

С появлением технологий реального времени (автономные транспортные средства, телемедицина, промышленный IoT) требования к скорости доступа к данным радикально изменились:4
- **Задержки субмиллисекундного уровня** – необходимы для систем принятия решений в реальном времени
- **Пропускная способность** – современные SSD уже приближаются к пределам интерфейсов PCIe 5.0
- **Гетерогенные рабочие нагрузки** – необходимость одновременного обслуживания запросов с разными требованиями к IOPS и latency.

Цифровые носители имеют ограниченный срок жизни, что создает серьезные риски:
- **Физическая деградация** – HDD имеют средний срок службы 3-5 лет, SSD – ограниченное число циклов записи.
- **Технологическое устаревание** – носители и форматы данных устаревают быстрее, чем физически разрушаются.
- **Битовая гниль (bit rot)** – постепенная деградация данных на физических носителях.
- **Миграция данных** – необходимость регулярного переноса информации на новые носители.

В эпоху ужесточающегося регулирования (GDPR, 152-ФЗ) и участившихся кибератак проблемы безопасности выходят на первый план:
- **Шифрование данных** – как в состоянии покоя, так и при передаче.
- **Неизменяемость (immutability)** – защита от случайного или злонамеренного удаления/изменения.
- **Соответствие нормативным требованиям** – особенно в регулируемых отраслях (финансы, здравоохранение).
- **Геополитические ограничения** – требования о локализации данных в разных юрисдикциях.
## Перспективные технологии
Ученые и инженеры уже заглядывают в будущее, разрабатывая перспективные технологии. **HAMR (тепловая магнитная запись)** позволит еще больше увеличить плотность данных на жестких дисках. Ведутся эксперименты по использованию **синтетической ДНК** как носителя информации, обладающего фантастической плотностью хранения и долговечностью. И на горизонте уже виднеются **квантовые технологии хранения**, которые могут кардинально изменить наши представления о памяти.

- **Квантовые носители:** Использование свойств квантовых частиц для хранения невообразимых объемов данных в микроскопических объемах.
- **Синтетическая ДНК:** Один грамм ДНК теоретически может хранить все данные мира. Технология находится в зачаточном состоянии, но демонстрирует фантастическую плотность хранения.
- **HAMR (Heat-Assisted Magnetic Recording):** Технология для HDD, использующая локальный нагрев для записи на более плотные магнитные слои, что позволит еще больше увеличить емкость дисков.

# Алгоритмы хранения информации
## Как работает сжатие
Любой вид связи, который мы используем, должен обладать одним важным свойством, без которого обмен информацией теряет всякий смысл. Это свойство очень хорошо сформулировал **Клод Шенон** ещё в 1948 году и звучало оно так: "Главное свойство системы связи заключается в том, что она должна точно или приближённо воспроизвести в определённой точке пространства и времени некоторое сообщение, выбранное в другой точке".
Казалось бы, это и так логично, что мы отправляем, то мы и получаем. В чём проблема?
Проблема в том, что вся эта информация передаётся по физическим каналам. Будь это компьютерный кабель, спутниковая антенна или даже оптический диск, на который мы записываем информацию. Любой физический канал подвержен внешнему воздействию, в результате которого исходные данные могут очень сильно исказиться, что, собственно, и происходило на практике, пока учёные не придумали две ключевые идеи, которые значительно повысили надёжность передачи данных.
Первое - это добавлять в передаваемую информацию дополнительные данные для проверки её корректности. Вторая, вместо исходной информации передавать лишь её компактное описание, что в разы сократит объём передаваемых сообщений.
Для этих целей у каждой стороны должны быть реализованы кодер и декодер, которые будут упаковывать, проверять и распаковывать корректно дошедшую информацию в исходный вид. Так родилась идея **сжатие**, которая получила особое распространение в эпоху развития компьютерных технологий.
Суть компьютера в том, чтобы хранить, обрабатывать и выдавать информацию, объёмы которые безграничны, в отличие от памяти, которая имеет свойство очень быстро заканчиваться в ходе её безрассудного транжирства. Поэтому, чем меньше информация занимает место в памяти, тем больше этой информации в памяти может быть.
Нам нужен такой алгоритм, который бы принимал на вход данные в исходном виде, а на выходе выдавал какую-то закодированную последовательность, которая по размеру будет меньше исходной информации. И нужен второй алгоритм, который бы принимал на вход закодированную последовательность, а на выходе выдавал исходную информацию без потери её смысла.
![[Pasted image 20251028181019.png]]
Всё, что мы можем сделать, чтобы информация стала весить меньше, чем была, - это просто удалить из неё какую-то часть данных. Но какую?
Возьмём такое изображение и такой вот текст. Что мы можем о них сказать?
![[Pasted image 20251028181047.png]]
Ну, например, то, что одни цвета встречаются чаще, а другие встречаются реже. То же самое можно сказать и о буквах текста. Одни буквы встречаются чаще, другие реже. Такая особенность характерна для любой информации, имеющей смысл. Например, если мы рисуем пейзаж, то небо у нас будет голубого цвета, а трава будет зелёного. Ну а если мы пишем письмо на английском языке, то по статистике самый встречающиеся буквы окажется буква E. Затем T, далее A и так далее.
![[Pasted image 20251028181129.png]]
Из-за того, что как часто, так и редко встречающиеся элементы информации содержат одинаковое количество бит, то такое превышение количества одного вида информации над другим порождает *избыточность*. Но что, если информация будет случайной? Например, изображение будет состоять из пикселей разных цветов. А текст будет состоять из разных неповторяющихся букв.
![[Pasted image 20251028181220.png]]
Такая информация избыточности не имеет. Почему это важно? Потому что именно в ней и заключается суть сжатия: в удалении избыточной информации. Если её нет, то сжать данные практически невозможно. Если есть, то мы получаем файл, в котором избыточности много, а на выходе выдаём файл, в котором избыточности мало. Вопрос только в том, как же нам удалить избыточность так, чтобы впоследствии её можно было восстановить.
Ответ очень прост. Никак!
Потому что, не имея никаких зацепок для восстановления, восстановить нам ничего не удастся. Поэтому вместо удаления мы будем её просто на что-то заменять. Для начала представим наше изображение как набор шестнадцатиричных байт, идущих в одну строку.
![[Pasted image 20251028181322.png]]
Попытка заменить каждый байт на какой-то другой байт, разумеется, в плане количества данных ничего не изменит. Поэтому заменять мы будем не один байт, а сразу целую последовательность байтов, что в перспективе может очень сильно сократить их длину.
### Алгоритм RLE (run-length encoding)
На основе этой идеи родился алгоритм RLE (run-length encoding), который считывает данные и ищет в них одинаковые последовательности, идущие друг за другом. В случае с нашей картинкой элементом такой последовательности будет являться 1 пиксель, состоящий из трёх байт.
![[Pasted image 20251028181433.png]]Теперь вместо этой цепочки мы оставим только один её элемент, перед которым укажем общее количество элементов, которое в ней было. Иными словами, сколько раз этот элемент повторяется.
![[Pasted image 20251028181503.png]]
Для того, чтобы при разжатии не возникала путаница, какая группа байт является цветом пикселя, какая обозначает число повторов, мы будем количество этих повторов задавать абсолютно для каждой группы элементов, даже если она состоит всего из одного пикселя.
![[Pasted image 20251028181534.png]]
Таким образом, вместо 75 байт мы получаем 28.
![[Pasted image 20251028181559.png]]
Разделив полученный размер картинки на размер исходной картинки, мы получаем число, называемое **коэффициентом сжатия**. Разделив исходный размер на итоговый, мы получаем число, называемое **фактором сжатия**. Соответственно, если коэффициент меньше одного, а фактор больше одного, то сжатие считается успешным.
![[Pasted image 20251028181632.png]]
`Но разве может так получиться, что после сжатия данных размер файла вырастет ещё больше, чем был?`
Давайте проверим. Возьмём наш текст (EXAGGERATION) в кодировке **ASCII** и применим к нему всё тот же алгоритм RLE по той же самой схеме.
![[Pasted image 20251028181745.png]]
Только теперь элементом последовательности будет являться не один пиксель, а один символ. Что мы видим? Текст увеличился более чем в полтора раза.
![[Pasted image 20251028181807.png]]
Дело в том, что хоть он и имеет избыточность, повторяющихся байт подряд в нём очень мало. Да, мы, конечно, можем считать не только количество повторов, но и количество отсутствий повторов, записывая это число со знаком минус. И хоть в некоторых случаях это действительно даст положительный результат в виде сжатия, в нашем примере не сработало даже это.
![[Pasted image 20251028181837.png]]
Текст снова увеличился в своём размере, а это означает только одно. Алгоритм **RLE** подходит только для определённых видов данных, которые содержат в себе много длинных и последовательных цепочек байтов, как, например, в случае с такими простыми иконками, содержащие в себе последовательно повторяющиеся цвета.
![[Pasted image 20251028181906.png]]
Для осмысленного текста или для фотографий, где соседние пиксели имеют, как правило, немного разные оттенки, такой алгоритм неэффективен. Раз универсального решения в очередной раз создать не удалось, значит, снова будем изобретать новые алгоритмы, способные решить нашу задачу.
### Алгоритм Хаффмана
Примерно так и думал Дэвид Хаффман в 1952 году, учась в аспирантуре Массачусетского университета. Именно там, во время написания курсовой работы он придумал алгоритм, который стал одним из основных алгоритмов сжатия во всём мире.
В алгоритме Хаффмана вместо замены целых последовательностей мы будем менять каждый символ на код переменной длины. Идея состоит в том, чтобы часто встречающиеся символы заменять на короткие коды, а редко встречающиеся символы заменять на более длинные коды. Причём каждый такой код не может иметь в начале ту последовательность бит, которая уже являлась чьим-то кодом. То есть, если первый код равен 0, то с 0 больше никто начинаться не может. Если код состоит из 10, то все следующие коды начинаться с последовательности 10 тоже не могут.
![[Pasted image 20251028182017.png]]

Такие коды, придётся воспользоваться бинарным деревом. Вначале мы просто идём по тексту, считаем, сколько раз встретился каждый символ, и записываем это в таблицу частотностей.
![[Pasted image 20251028182122.png]]
Затем все эти символы мы сортируем в порядке убывания их частотности, заносим их в специальный список и добавляем в наше пустое дерево в качестве его листьев.
![[Pasted image 20251028182143.png]]
И именно с них, снизу вверх, мы будем это дерево формировать. На каждой итерации мы выбираем из списка два символа с наименьшей частотностью и создаём для них новый родительский узел. Частотностью этого узла будет являться сумма частот двух его детей. Самих же детей мы из списка свободных узлов удаляем, а родительский узел наоборот заносим.
![[Pasted image 20251028182227.png]]
На следующей итерации мы снова выбираем из списка два из четырёх оставшихся узла с наименьшей частотностью и снова создаём для них родительский узел.
![[Pasted image 20251028182257.png]]
Все эти действия мы продолжаем делать до тех пор, пока в нашем списке не останется ровно один узел. Именно он и станет корнем нашего дерева.
![[Pasted image 20251028182311.png]]
![[Pasted image 20251028182323.png]]
Благодаря тому, что мы начинали строить дерево самых редко встречающихся в тексте символов, путь до них от корня будет самым длинным. А до символов встречающихся чаще всего путь будет самым коротким.
Почему это важно? Потому что каждая ветка на этом пути будет формировать код символа. Ветка слева обозначает 0, ветка справа – 1.
![[Pasted image 20251028182406.png]]
В итоге весь этот путь от корня до каждого символа в виде единицы нулей и станет его персональным кодом, на который мы его и заменим.
![[Pasted image 20251028182426.png]]
Соответственно, чем меньше путь, тем код символа будет короче. Чем больше путь, тем код символа будет длиннее.
![[Pasted image 20251028182510.png]]
Для того, чтобы декодер смог декодировать эту сжатую информацию, когда придёт время, мы должны в самое начало сжатых данных добавить таблицу частотности символов, на основе которой декодер вновь построит дерево кодов.
![[Pasted image 20251028182536.png]]
Затем он будет считывать каждый бит сжатых данных, начиная сначала. Если там окажется 0, то мы совершим переход в дереве по левой ветке. Если там окажется 1, то мы совершим переход по правой.
![[Pasted image 20251028182651.png]]
Таким образом, считывая бит забита, мы рано или поздно будем добираться до каждого символа и записывать его в итоговый файл. Так выглядит классическая реализация алгоритма Хаффмана.
Главный его *минус* - это таблица частотностей, которую мы вынуждены хранить в начале файла и которая может заметно увеличивать его размер. Как эту проблему решить?
Ну, например, просто изначально эту таблицу не создавать, а сразу начать генерировать дерево кодов. Возможно ли такое? Как оказалось, да. Берём первый символы. Так как его в дереве ещё нет, то никакого кода для него, разумеется, не существует. Поэтому просто записываем его в сжатый файл в исходном виде. После этого вносим этот же символ в наше пустое дерево, но не так, как мы это делали раньше, а немного по другим правилам.
![[Pasted image 20251028183320.png]]
Теперь элементом, добавляемым в дерево, будет не один узел, а такая вот тройка узлов, которая состоит из родительского узла и двух его детей. Левым ребёнком будет узел заглушка, называемым **escape**, а правым ребёнком будет наш символ, который мы хотим добавить в дерево. Шаг к левому ребёнку снова обозначает код 0, шаг к правому – код 1. Кроме этого, каждый узел должен иметь свой вес. Вес узла с нашим символом будет равняться его частотности. Вес родительского узла всегда будет 0, а вес родительского узла равняется сумме весов его детей.
Помимо этого, наше кодовое дерево должно обладать двумя важными свойствами, которые мы не должны нарушать. Вес родителя должен равняться сумме весов его детей, о чём мы уже сказали. А вес правого узла не должен быть меньше веса левого. Если эти свойства будут нарушены, а они будут, значит, нам придётся дерево модифицировать.
Берём следующий символ. Так как его в дереве тоже нет, то мы в это дерево должны вставить и его тройку.
![[Pasted image 20251028183723.png]]
Это и все последующие тройки, которые мы будем в дерево добавлять, всегда будут подставляться вместо *escape* узла. На сжатый файл мы должны записать не только новый добавленный в дерево символ, но и код до escape символа, вместо которого мы эти узлы вставили. В данном случае это код 0. Если мы теперь посмотрим на дерево, то заметим, что данная подстановка сразу же нарушила первое правило.
Поэтому после каждого изменения дерева мы должны будем пересчитывать вес родительских узлов.
![[Pasted image 20251028183755.png]]
По этой же логике добавляем дерево, третий символ и приходим к нарушению второго правила. Левый узел оказался больше правого.
![[Pasted image 20251028183819.png]]
Чтобы это исправить, просто меняем ветви местами.
![[Pasted image 20251028183840.png]]
Следующий символ *A* уже в дереве есть. В этом случае нам не нужно в дерево ничего добавлять. Мы всего лишь увеличиваем вес этого узла на 1, перерасчитываем вес родительских узлов и добавляем в сжатый файл код до нашего символа.
![[Pasted image 20251028183958.png]]
Двигаясь по той же самой схеме, постоянно модифицируя дерево, мы получаем сжатую последовательность, которую теперь декодер сможет восстановить без всяких дополнительных таблиц.
![[Pasted image 20251028184029.png]]
Он знает, что первым символом всегда будет являться несжатый символ, который он по тем же самым правилам добавит в дерево и запишет этот символ в итоговый файл. Далее он получит код ноль, который говорит о том, что в дереве нужно перейти к левому ребёнку и добавить туда тройку символом B, которая следует за нулём. Затем снова добавит символ B в итоговый файл и продолжит всё по аналогии, строя, модифицируя и переходя по дереву точно так же, как это делал кодер.
Такой алгоритм получил название **адаптивный метод Хаффмана**. Оба они относятся к так называемым алгоритмам энтропийного сжатия, где мы, используя статистику частотности символов, грубо говоря, усредняем вероятности их появления. Сама же **энтропия** - это величина, показывающая, какое количество бит в среднем приходится на один символ. **Мена** же показывает возможную степень сжатия.
Например, энтропия усреднённого английского текста составляет примерно 3,2 бит на букву. Это означает, что текстовый файл в ASCII кодировке, где на каждую букву приходится 8 бит, в среднем получится сжать примерно в 2,5 раза.
Основной недостаток алгоритма Хаффмана в том, что он кодирует каждый символ определённым количеством бит, что в некоторых случаях снижает степень сжатия. Решить эту проблему способно **арифметическое кодирование**.
### Арифметическое кодирование
Суть его в том, что мы снова считаем частотность появления символов и записываем их в таблицу в виде таких вот коэффициентов, обозначающих вероятность их появления. Только ещё в самом конце текста мы добавим некий символ, который будет обозначать конец строки.
![[Pasted image 20251028184320.png]]
Зачем это нужно, станет понятно в процессе декодирования. Далее мы отмеряем рабочий отрезок от нуля до одного и разбиваем его на отрезки, прямо пропорциональные нашим вероятностям. То есть первый отрезок соответствует букве A и составляет 40% от длины. Второй соответствует букве B с 20% и так далее.
![[Pasted image 20251028184352.png]]
Теперь, чтобы закодировать наш текст, берём самый первый символ. Ему соответствует первый отрезок, который теперь вместо основного становится нашим рабочим отрезком, на котором мы точно также в процентном соотношении должны разместить все наши точки.
![[Pasted image 20251028184425.png]]
Второй символ B, он соответствует второму отрезку, поэтому теперь тот становится рабочим отрезком, на котором мы снова расставляем точки.
![[Pasted image 20251028184447.png]]
Всё это повторяется до тех пор, пока мы не добираемся до самого последнего символа строки. К этому моменту у нас останется всего один отрезок с двумя точками. Так вот, сжатой информацией станет дробная часть числа между двумя точками, которые можно записать минимальным количеством знаков.
![[Pasted image 20251028184545.png]]
Для того, чтобы из этого числа восстановить исходную информацию, нам потребуется вместе с сжатой информацией хранить и таблицу вероятностей, которую использует декодер для построения отрезков точно по такому же сценарию. Мы разбиваем его на пять частей и смотрим, в какую часть попадает наше сжатое число.
![[Pasted image 20251028184624.png]]
Попадает оно в первый отрезок. Значит, первая буква исходного текста A. Теперь снова в качестве рабочего отрезка выбирается тот, в котором оказалась наша точка. Снова делим его на пять частей и снова смотрим, куда попало наше число. Куда оно попадёт, та буква и будет второй буквой исходного сообщения.
![[Pasted image 20251028184658.png]]
А чтобы декодер понял, в какой момент создания отрезков ему нужно остановиться, мы добавили специальный символ, обозначающий конец строки.
### Алгоритм LZ77
В 70-х годах начинают активно создаваться словарные методы сжатия, которые вообще не используют статистику частотности символов и не используют никаких кодов переменной длины. Вместо этого они кодируют целые последовательности символов, которые ранее встречались в словаре. А в качестве сжатых данных записывают лишь метки на смещения совпадений в этом словаре.
Впервые идею сжатия данных с использованием словаря в 1977 году осуществили два израильских математика Якоб Зив и Абрахам Лемпель. Алгоритм был назван по первым буквам их фамилий **LZ77**. Реализуется он на основе так называемого скользящего окна. Это всего лишь ограниченная область памяти, с которой мы работаем в текущей итерации.
Вся эта ограниченная область условно разбивается на две части. Левая часть - это словарь. Туда помещаются данные, которые уже прошли обработку. Правая часть - это буфер. Туда помещаются данные, которые только предстоит сжать.
![[Pasted image 20251028185019.png]]
Вначале мы берём исходные данные и помещаем их в буфер в том размере, в котором они туда влезут.
![[Pasted image 20251028185123.png]]
Задача кодера – найти в словаре смещение первого символа из нашего буфера. Но так как словарь изначально пуст, то мы найти никаких совпадений в нём, разумеется, не можем. Поэтому в качестве смещения первым числом записываем 0. Вторым числом мы должны записать длину совпавшей цепочки. Но так как никаких совпадений не было, снова пишем 0. В конце мы записываем сам символ, следующий за совпавшей цепочкой. Так как совпадений не было, то за несуществующей цепочкой идёт символ, который мы сейчас рассматриваем.
![[Pasted image 20251028185151.png]]
Далее мы сдвигаем наши данные на один символ справа налево, перенося первый обработанный символ в словарь.
![[Pasted image 20251028185207.png]]
Так как для второго и третьего символа мы в словаре совпадений тоже не найдём, точно также записываем нули вместе с этими символами.
![[Pasted image 20251028185250.png]]
Но вот совпадение с четвёртым символом в словаре есть. Смещение до него считается от конца словаря. Поэтому записываем тройку и увеличиваем обрабатываемую цепочку на один символ в буфере и словаре, чтобы проверить её на предмет совпадений.
![[Pasted image 20251028185343.png]]
Совпадений нет, поэтому общая длина совпавшей цепочки составляет один символ. В конце мы снова дописываем символ, следующий за совпавшей цепочка, и смещаем данные на длину обработанных символов.
Следующий символ снова имеет совпадение в словаре в единственном экземпляре, но кодер этого заранее не знает, так как есть вероятность, что где-то левее есть более длинная цепочка совпадений, поэтому он идёт дальше и доходит до последнего совпадения.
![[Pasted image 20251028185432.png]]
Если эта цепочка оказывается меньше, то используем предыдущее совпадение. Если она оказывается больше или равна, то остаёмся здесь.
![[Pasted image 20251028185510.png]]
Сдвигаем данные ещё раз. Снова идём по словарю в поисках совпадений. Доходим до последнего символа. И просканировав следующие символы за ним, обнаруживаем, что цепочка в буфере и словаре совпадает на целых четыре символа, что мы и записываем в сжатый файл.
![[Pasted image 20251028185606.png]]
Хорошо. Как теперь декодеру из этой последовательности восстановить данным исходный вид? На самом деле очень просто. Ему нужно сделать практически то же самое: создать буфер и словарь.
![[Pasted image 20251028185659.png]]
В буфер поместить сжатые данные и, основываясь на метках, брать символы из словаря по смещению, записанном в первом параметре метки, не в том количестве, которое указано во втором параметре. Нулевые метки означают, что совпадений в словаре не было. Поэтому мы просто берём символ из третьего параметра, записываем его в словарь и в итоговый файл.
![[Pasted image 20251028185731.png]]
Проделываем то же самое ещё с двумя метками.
![[Pasted image 20251028185752.png]]
И дойдя до четвёртой метки, видим, что нам нужно найти в словаре третий символ с конца и скопировать оттуда один символ. в итоговый файл. Делаем то же самое с двумя оставшимися метками и получаем исходный текст.
![[Pasted image 20251028185816.png]]
Здесь важно понимать, что чем больше будет размер скользящего окна, тем дольше в нём будет производиться поиск и тем дольше будет работать сам алгоритм. Но если окно будет слишком маленьким, то мы не сможем находить длинные одинаковые цепочки, так как они туда просто не влезут.
Что касается размера окна декодера, то он может быть больше либо таким же, как у кодера, но точно не может быть меньше. Иначе рано или поздно кодируемые кодером цепочки просто не влезут в наше скользящее окно, и восстановление данных станет невозможным.
![[Pasted image 20251028185906.png]]
Цель этого примера максимально компактно показать суть работы алгоритма. Поэтому в том, что алгоритм привёл нас к увеличению размера файла, ничего страшного нет. Это лишь ещё раз показывает, что есть такие данные, для которых тот или иной алгоритм подходит не очень. Плюс идея скользящего окна тоже вносят свои ограничения.
### LZ78
Поэтому всё те же учёные продолжили свою работу и спустя всего год предложили второй алгоритм со словарным методом сжатия данных под названием LZ78. Этот алгоритм больше не использует скользящее окно. Вместо этого он использует словарь, размер которого ограничен только объёмом памяти и из которого больше никогда ничего не удаляется. Словарь состоит из строк, нумерация которых начинается с единица. Изначально он пуст, заполняется по мере обработки поступаемых данных.
![[Pasted image 20251028190021.png]]
Мы получаем на вход первый символ и ищем ему соответствие в словаре. Такого символа нет. Поэтому вжатый файл мы записываем метку, состоящую из двух параметров. Это указатель на найденную строку в словаре и символ, следующий за данными, которые в словаре были обнаружены. Так как мы ничего не нашли, то записываем ноль и символ A. В словарь же мы помещаем ту группу символов, для которой в данный момент в словаре производился поиск.
![[Pasted image 20251028190129.png]]
То же самое происходит со вторым и третьим символом.
![[Pasted image 20251028190151.png]]
А дойдя до четвёртого, мы обнаруживаем его совпадение в словаре в строке с номером 1. Поэтому мы увеличиваем обрабатываемую цепочку на один символ и ищем в словаре совпадение уже для неё.
![[Pasted image 20251028190214.png]]
Совпадения нет, поэтому в словаре идёт та цепочка, для которой производился поиск. Ну а в качестве метки первым параметром идёт номер строки, в которой было найдено совпадение для символа А. Ну а вторым параметром выступает символ, следующий за данными, которые были в словаре найдены, то есть символ C.
![[Pasted image 20251028190341.png]]
Далее берём следующий символ и проделываем те же самые действия по аналогии.
![[Pasted image 20251028190435.png]]
Чтобы восстановить исходный текст по этим меткам, нужно сделать практически всё то же самое, только теперь в роли единицы входных данных будет выступать не символ, а метка.
Берём первую метку, по нулю определяем, что её символу в словаре соответствия нет. Записываем этот символ в итоговый файл и снова заносим его в словарь, как это делал кодер.
![[Pasted image 20251028190516.png]]
![[Pasted image 20251028190529.png]]
Дойдя до метки, по которой соответствие было найдено, мы достаём его из словаря в строке с номером один, дописываем ему символ C и добавляем в наш файл.
![[Pasted image 20251028190556.png]]
Делаем то же самое с тремя оставшимися метками и получаем исходный текст.
![[Pasted image 20251028190610.png]]
**LZ77** и **LZ78** стали первыми двумя алгоритмами сжатий, основанных на словаре. В течение следующих лет их постоянно будут пытаться усовершенствовать, сводя к минимуму их недостатки, в результате чего **LZ77** получит улучшенную версию в виде алгоритма **LZSS**.
![[Pasted image 20251028190728.png]]
В этом алгоритме буфер заменён на циклическую очередь, словарь превращён в двоичное дерево, а три параметра метки сокращены до двух. **LZ78** тоже не остался в стороне и был доработан версией **LZW**, в которой удалось избавиться от второго параметра метки благодаря немного другой схеме использования словаря.
В 90-х годах алгоритмов на основе идеи **LZ** становится ещё больше. Все они получают общее название алгоритмы семейства **LZ**.
Несмотря на то, что алгоритмов существует так много, все они по-прежнему продолжают использоваться для сжатия информации. Например, комбинация **LZ77** и Хаффмана произвела на свет алгоритм **DEFLATE**, который используется в **PNG** файлах, **ZIP** архиваторе и так далее. **LZSS** используется в архиваторе **RAR**, **LZW** в картинках **GIF**, LZMA **в** архиваторе **7-ZIP** и так далее, и так далее.
![[Pasted image 20251028190847.png]]
Всё, что мы сейчас разобрали, называется **сжатием без потерь**. То есть после процедуры сжатия мы можем восстановить исходные данные ровно в том виде, в котором они были изначально. Это работает абсолютно для любых видов данных. Текстовые файлы изображения, архиваторы вроде того же **ZIP** и так далее.
Казалось бы, на этом тему сжатия можно было бы и закрыть, если бы не одна маленькая деталь, касаемая органов нашего восприятия. Если в случае с текстом мы не можем позволить себе потерять при сжатии ничего, потому что иначе мы не сможем распознать заложенный в текст смысл, то в случае с медиа-данными, такими как фотографии, музыка или видео, дело обстоит немного иначе.
К примеру, возьмём такую фотографию размером 6.000 на 4.000 пикселей.
![[Pasted image 20251028191001.png]]
Если каждый пиксель представляется 3 **RGB** байтами, то общий вес такой фотографии составит 68 МБ. А теперь мы возьмём такую вот фотографию и визуально сравним два этих изображения.
![[Pasted image 20251028191045.png]]
Думаю, многие, глядя на два этих фото, скажут, что они абсолютно одинаковые. Однако, если мы посмотрим в свойствах, сколько весит второе изображение, то увидим всего 4 МБ, что в 17 раз меньше, чем вес первого изображения. Дело в том, что из второй картинки выкинуто достаточное количество информации, чтобы значительно уменьшить её вес, но недостаточно для того, чтобы наш глаз ощущал какие-то различия. А раз он их не ощущает, то зачем нам хранить всю исходную информацию изображения целиком, если мы можем уже изначально её сжать, выкинув оттуда всё то, на что наш глаз не среагирует.
Именно поэтому со временем появился второй вид **сжатия с потерями**. Если в случае с сжатием без потерь мы пытались избавиться от избыточности путём её замены, то в алгоритмах сжатия с потерями мы должны найти и полностью удалить несущественную для нашего восприятия информацию. Причём теперь это возможно сделать даже там, где той избыточности, о которой мы сегодня говорили, вообще нет. Это касается как больших изображений и видео, так и аудиофайлов, в которых наше ухо тоже не услышит никакой разницы, если оттуда убрать некоторое количество информации.
О том, как именно это работает, лучше всего рассматривать на конкретных форматах, таких как **JPEG**, **MP3** и так далее, потому что каждый такой формат довольно уникален.