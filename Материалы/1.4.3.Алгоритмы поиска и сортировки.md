---
tags: 
Создана: "2025-12-07"
---
# Алгоритмы поиска
Задачи поиска и сортировки для массивов и файлов – очень часто встречающиеся задачи при работе с данными. Примерами множеств данных могут служить телефонные справочники, оглавления в книгах, списки книг в библиотеках, списки сотрудников организаций и т. д.
## Поиск в неупорядоченных массивах
Данный алгоритм еще называется алгоритмом **последовательного поиска** или **прямым поиском**, он является самым простым и очевидным. Его основная идея заключается в последовательном просмотре каждого элемента массива от начала до конца и сравнении его с искомым значением.
### Принцип работы алгоритма
Алгоритм работает по следующей схеме:
1. **Начало**: Получаем на вход массив и искомое значение
2. **Итерация**: Последовательно перебираем элементы массива, начиная с первого
3. **Сравнение**: Для каждого элемента проверяем, равен ли он искомому значению
4. **Результат**:
    - Если найден совпадающий элемент – возвращаем его позицию (индекс)
    - Если весь массив просмотрен и элемент не найден – возвращаем специальное значение (обычно `-1` или `None`)
### Детальное описание шагов
#### Шаг 1: Инициализация
- Принимаем массив `arr` и искомое значение `target`
- Определяем длину массива `n = len(arr)`
- Устанавливаем начальный индекс `i = 0`
#### Шаг 2: Основной цикл поиска
- Пока `i < n` (индекс не вышел за границы массива):
    - Если `arr[i] == target`:
        - Элемент найден, возвращаем индекс `i`
    - Иначе:
        - Увеличиваем индекс `i = i + 1` и переходим к следующему элементу
#### Шаг 3: Завершение
- Если цикл завершился (просмотрели весь массив):
    - Возвращаем значение, указывающее на отсутствие элемента (например, `-1`)
### Реализация
```python
def linear_search(arr, target):
    for i in range(len(arr)):
        if arr[i] == target:
            return i
            
    return -1
```
### Анализ сложности алгоритма
- **Худший случай**: $\mathcal{O}(n)$ – когда искомый элемент находится в конце массива или отсутствует
- **Средний случай**: $\mathcal{O}(n/2) \approx \mathcal{O}(n)$ – в среднем нужно просмотреть половину массива
- **Лучший случай**: $\mathcal{O}(1)$ – когда искомый элемент находится в начале массива
## Дихотомический поиск в упорядоченном массиве
**Дихотомический поиск** (также известный как бинарный поиск или половинное деление) – это эффективный алгоритм поиска элемента в **отсортированном массиве**. Основная идея заключается в последовательном делении массива на две части и исключении одной из них из дальнейшего рассмотрения на каждом шаге.
### Принцип работы алгоритма
Алгоритм работает по принципу **"разделяй и властвуй"**:
1. Находим средний элемент массива
2. Сравниваем его с искомым значением
3. Если средний элемент равен искомому – поиск завершен
4. Если искомое значение **меньше** среднего элемента – продолжаем поиск в левой половине
5. Если искомое значение **больше** среднего элемента – продолжаем поиск в правой половине
6. Повторяем процесс, пока не найдем элемент или не убедимся в его отсутствии

На каждом шаге размер области поиска уменьшается вдвое:
- После $1$-го шага: осталось $n/2$ элементов
- После $2$-го шага: осталось $n/4$ элементов
- После $k$-го шага: осталось $n/2^k$ элементов
Поиск завершается, когда $n/2^k \le 1$, то есть $k \ge \log_2{n}$.
### Детальное описание шагов
#### Инициализация
- Устанавливаем левую границу: `left = 0`
- Устанавливаем правую границу: `right = n-1` (где n – длина массива)
#### Основной цикл
1. Пока `left ≤ right`:
    - Вычисляем средний индекс: `mid = (left + right) // 2`
    - Если `arr[mid] == target`: элемент найден, возвращаем `mid`
    - Если `arr[mid] < target`: сдвигаем левую границу `left = mid + 1`
    - Если `arr[mid] > target`: сдвигаем правую границу `right = mid - 1`
2. Если цикл завершился: элемент не найден
### Реализация
```python
def binary_search(arr, target):
    left = 0
    right = len(arr) - 1
    
    while left <= right:
        mid = left + (right - left) // 2
        
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            left = mid + 1
        else:
            right = mid - 1
            
    return -1
```
### Анализ сложности алгоритма
- **Худший случай**: $\mathcal{O}(\log{n})$ – элемент не найден или находится на границе
- **Средний случай**: $\mathcal{O}(\log{n})$ – в среднем нужно просмотреть половину массива
- **Лучший случай**: $\mathcal{O}(1)$ – когда искомый элемент находится в начале массива
# Алгоритмы сортировки
**Сортировка** – это процесс упорядочения некоторого множества элементов, на котором определены отношения порядка >, <, ≥, ≤, =. Когда говорят о сортировке, подразумевают упорядочение множества элементов по возрастанию или убыванию. В случае наличия элементов с одинаковыми значениями, в упорядоченной последовательности они располагаются рядом друг с другом в любом порядке. Хотя иногда, бывает полезно сохранить первоначальный порядок элементов с одинаковыми значениями.

Алгоритмы сортировки имеют большое практическое применение. Их можно встретить почти везде, где речь идет об обработке и хранении больших объемов информации. Некоторые задачи обработки данных решаются проще, если данные упорядочены.

Традиционно различают внутреннюю сортировку, в которой предполагается, что данные находятся в оперативной памяти, и важно оптимизировать число действий программы (для методов, основанных на сравнении, число сравнений, обменов элементов и пр.), и внешнюю, в которой данные хранятся на внешнем устройстве с медленным доступом (диск, лента и т. д.) и, прежде всего, надо снизить число обращений к этому устройству.
## Пузырьковая сортировка (Bubble Sort)
**Пузырьковая сортировка** – это простой алгоритм сортировки, который многократно проходит по массиву, сравнивает соседние элементы и меняет их местами, если они находятся в неправильном порядке. Название происходит от аналогии с пузырьками воздуха, которые всплывают в воде – более легкие (меньшие) элементы "всплывают" к началу массива.
### Принцип работы алгоритма
Алгоритм работает по следующей схеме:
1. Проходим по массиву от начала до конца
2. Сравниваем каждую пару соседних элементов
3. Если элементы расположены в неправильном порядке (предыдущий больше следующего), меняем их местами
4. Повторяем процесс до тех пор, пока массив не будет полностью отсортирован
### Детальное описание шагов
1. **Инициализация**: Получаем массив `arr` размером `n`
2. **Внешний цикл**: Выполняем `n-1` проходов по массиву
3. **Внутренний цикл**: Для каждого прохода проходим по неотсортированной части массива
4. **Сравнение**: Сравниваем текущий элемент `arr[j]` со следующим `arr[j+1]`
5. **Обмен**: Если `arr[j] > arr[j+1]`, меняем их местами
6. **Завершение**: Когда за весь проход не выполнено ни одного обмена, массив отсортирован
### Реализация
```python
def bubble_sort_naive(arr):
    n = len(arr)
    
    for i in range(n - 1):
        print(f"\nПроход {i + 1}:")
        
        for j in range(n - 1):
            print(f"  Сравниваем arr[{j}]={arr[j]} и arr[{j+1}]={arr[j+1]}", end="")
            
            if arr[j] > arr[j + 1]:
                arr[j], arr[j + 1] = arr[j + 1], arr[j]
                print(f" -> МЕНЯЕМ местами")
            else:
                print(f" -> не меняем")
    
    return arr
```
### Анализ сложности алгоритма
- **Худший случай**: $\mathcal{O}(n^2)$ – массив отсортирован в обратном порядке
- **Средний случай**: $\mathcal{O}(n^2)$ – случайный порядок элементов
- **Лучший случай**: $\mathcal{O}(n)$ – массив уже отсортирован (с оптимизацией алгоритма)
### Преимущества
1. **Простота реализации** – алгоритм легко понять и написать
2. **Сортировка на месте** – не требует дополнительной памяти
3. **Стабильность** – не меняет порядок равных элементов
4. **Адаптивность** – оптимизированные версии эффективны для почти отсортированных массивов
5. **Образовательная ценность** – отличный пример для изучения основ алгоритмов сортировки
### Недостатки
1. **Низкая производительность** – $\mathcal{O}(n^2)$ делает его непрактичным для больших массивов
2. **Много обменов** – даже в оптимизированных версиях
3. **Неэффективен на больших данных** – значительно медленнее более сложных алгоритмов
## Сортировка слиянием (Merge Sort)
**Сортировка слиянием** – это эффективный, стабильный алгоритм сортировки, работающий по принципу **"разделяй и властвуй"**. Алгоритм делит массив на две равные (или почти равные) части, рекурсивно сортирует каждую часть, а затем объединяет (сливает) отсортированные части в один отсортированный массив.
### Принцип работы алгоритма
Алгоритм состоит из трех этапов:
1. **Разделение** (Divide): Рекурсивно делим массив на две половины, пока не получим подмассивы размером 1 элемент (которые по определению являются отсортированными)
2. **Властвование** (Conquer): Рекурсивно сортируем подмассивы
3. **Слияние** (Combine): Объединяем отсортированные подмассивы в один отсортированный массив
### Детальное описание шагов
Работает по принципу рекурсивного алгоритма
1. **Базовый случай**: Если массив содержит 0 или 1 элемент, он уже отсортирован
2. **Разделение**: Находим середину массива: `mid = len(arr) // 2`
3. **Рекурсивный вызов**:
    - Сортируем левую половину: `left = merge_sort(arr[:mid])`
    - Сортируем правую половину: `right = merge_sort(arr[mid:])`
4. **Слияние**: Объединяем отсортированные половины в один массив
### Реализация
```python
def merge_sort(arr):
    if len(arr) <= 1:
        return arr
    
    mid = len(arr) // 2
    
    left_half = merge_sort(arr[:mid])
    right_half = merge_sort(arr[mid:])
    
    return merge(left_half, right_half)


def merge(left, right):

    result = []
    i = j = 0
    
    while i < len(left) and j < len(right):
        if left[i] <= right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    
    result.extend(left[i:])
    result.extend(right[j:])
    
    return result
```
### Анализ сложности алгоритма
- **Худший случай**: $\mathcal{O}(n*\log{n})$
- **Средний случай**: $\mathcal{O}(n*\log{n})$
- **Лучший случай**: $\mathcal{O}(n*\log{n})$ – даже для уже отсортированного массива
### Преимущества
1. **Гарантированная сложность** – всегда $\mathcal{O}(n*\log{n})$, независимо от входных данных
2. **Стабильность** – сохраняет порядок равных элементов
3. **Параллелизуемость** – легко распараллелить (разные половины можно сортировать независимо)
4. **Внешняя сортировка** – подходит для сортировки данных, не помещающихся в оперативную память
5. **Предсказуемость** – одинаковое время выполнения для любых данных
### Недостатки
1. **Дополнительная память** – требует $\mathcal{O}(n)$ дополнительной памяти
2. **Не рекурсивная версия сложнее** – рекурсивная версия проще для понимания
3. **Не является адаптивной** – не ускоряется на частично отсортированных данных
4. **Overhead рекурсии** – рекурсивные вызовы могут быть дорогими для очень больших массивов
# Алгоритмы обработки символьных строк
## Алгоритм Кнута-Морриса-Пратта (KMП)
Алгоритм был открыт Дональд Кнутом и Вон Праттом и, независимо от них, Д. Моррисом. Результаты своей работы они совместно опубликовали в 1977 году. Алгоритм Кнута, Морриса и Пратта (КМП-алгоритм) является алгоритмом, который фактически требует только $\mathcal{O}(n)$ сравнений даже в самом худшем случае.

Рассматриваемый алгоритм основывается на том, что после частичного совпадения начальной части подстроки с соответствующими символами строки фактически известна пройденная часть строки и можно, вычислить некоторые сведения, с помощью которых затем быстро продвинуться по строке.

Основным отличием алгоритма Кнута, Морриса и Пратта от алгоритма прямого поиска заключается в том, что сдвиг подстроки выполняется не на один символ на каждом шаге алгоритма, а на некоторое переменное количество символов. Следовательно, перед тем как осуществлять очередной сдвиг, необходимо определить величину сдвига.

Если для произвольной подстроки определить все ее начала, одновременно являющиеся ее концами, и выбрать из них самую длинную (не считая, конечно, саму строку), то такую процедуру принято называть *префикс-функцией*.
В реализации алгоритма Кнута, Морриса и Пратта используется предобработка искомой подстроки, которая заключается в создании префикс-функции на ее основе. При этом используется следующая идея: если *префикс* (он же суффикс) строки длиной $i$ длиннее одного символа, то он одновременно и префикс подстроки длиной $i-1$. Таким образом, проверяем префикс предыдущей подстроки, если же тот не подходит, то префикс ее префикса, и т.д. Действуя так, находим наибольший искомый префикс.
### Основные области применения
#### Текстовый поиск и обработка
- **Поиск в текстовых редакторах** (`Ctrl+F` в браузерах, текстовых редакторах, IDE)
- **Поиск в базах данных** (поиск подстрок в текстовых полях)
- **Анализ логов** (поиск паттернов в лог-файлах серверов)
- **Обработка больших текстов** (книги, документы, статьи)
#### Текстовый поиск и обработка
- **Индексация веб-страниц** (поиск ключевых слов)
- **Автодополнение поисковых запросов**
- **Выделение поисковых терминов в результатах**
#### Системы контроля версий (Git, SVN)
- **Поиск изменений в коде**
- **Поиск определенных паттернов в истории коммитов**
- **Анализ diff-файлов**
#### Лексический анализ
- **Выделение токенов** (ключевых слов, идентификаторов, чисел)
- **Анализ регулярных выражений**
- **Подсветка синтаксиса**